---
title: "MFK Salmon River Chinook spawn time analysis: BMM workflow"
output:
  html_document:
    toc: true
    number_sections: true
    toc_depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: false
date: "2025-04-29"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(tidyverse)
library(here)
library(patchwork)
library(lemon)
library(ggeffects)
library(lme4)
library(mgcv)
library(gratia)
# source(here("R", "gg_theme.R"))
library(MuMIn)
```

```{r}
# Lower granite dam counts -----------------------------------------------------
# lgd_chinook <-tibble(year = c(2002,2003,2004,2005),
#                      spring_chinook = c(75025,70609,70742,26028),
#                      spring_jacks = c(2089,8295,4482,1258),
#                      all_chinook = c(109535, 98763, 94469, 43958)) |> 
#   mutate(year = as.factor(year))
```

## Goal

Describe variation in spawn timing and how it relates to environmental covariates.

## Study area and species

This study was conducted in the Middle Fork of the Salmon River (MFSR) in central Idaho (Fig. 1).

![Map of the Middle Fork Salmon River (MFSR) study area showing redd locations used in the analysis (2002-2005) and stream reaches.](images/MFsalmonRedds_GT2001_BigYellow_Apr24.jpg){width="50%"}

## Data prep and inspection

### Spawn timing data

Spawn timing data for Chinook salmon were collected from 2001 to 2005 in the MFSR (Fig. 1).

We removed data from 2001, and data from Knapp Creek and Cape Horn Creek, as these sites were not consistently sampled.

Because redds were not observed daily, we infered spawn dates as the initial date a completed redd was observed.

We joined each redd location to the NHD and assigned them a COMID, analogous to a stream reach. The COMID is used to link the spawn time data with covariate data associated with the stream reach on which it is located.

```{r load-spawn-data, echo=TRUE}
# data were compiled and clean in compile_mfsr_spawn.R and clean_mfsr_spawn.R
spawn_data <- read_csv(here("data", "russ_spawn", "mfsr_spawn_cleaned.csv"))

# remove bad data
spawn_data <- spawn_data |>
  filter(stream != "Knapp" & stream != "Cape Horn" & year != 2001) |> 
  mutate(year = as.factor(year), stream = as.factor(stream), COMID = as.factor(COMID), DATE = mdy(DATE)) |> 
  select(
    redd_id = UNIQUE_ID, COMID, spawn_date = DATE, stream, year, yday
  )

spawn_data
```

The data comprise `r nrow(spawn_data)` redd observation from `r length(unique(spawn_data$stream))` streams across `r length(unique(spawn_data$year))` years. The redds were observed between day `r min(spawn_data$yday)` and `r max(spawn_data$yday)`.

### Covariates

To test for environmental factors driving variation in spawn timing, we quantified associations with metrics describing thermal and physical conditions in stream reaches.

We selected covariates based on the following criteria: (1) they are known to influence spawn timing, (2) they are available for all streams, and (3) they are not highly correlated with each other.

Our focal independent variable were:

-   stream temperature (Â°C) - in-basin effect on how fast fish ripen and commit to spawning
-   stream discharge (cms) - out of basin year effect on when fish initially make it to spawn grounds
-   elevation (m above sea level)
-   stream gradient (slope)

#### Stream temperature

We used modeled daily average stream temperature values predicted at the stream segment (COMID) scale (Siegel et al. 2023; available from <https://zenodo.org/records/8174951>). These data were downloaded and filtered to 2001-2005 and for the MFSR HUC 6.

```{r}
# temp data (see siegel_mfsr_temps.R)
df_temp <- readRDS(here::here("data/siegel_temperature/siegel_mfsr_comid.RDS"))

xref_comid_stream <- spawn_data |> 
  distinct(COMID, stream) 

# clean up
df_temp <- df_temp |>
  select(COMID, date = tim.date, temp = prd.stream_temp) |> 
  mutate(
    yday = yday(date), 
    year = as_factor(year(date)), 
    COMID = as.character(COMID)) |> 
  filter(COMID %in% spawn_data$COMID) |>
  filter(year %in% c("2001","2002","2003","2004","2005")) |>
  left_join(xref_comid_stream, by = "COMID") 

# raw temp data 
head(df_temp)
```

##### Summarized thermal regimes by stream

```{r}
# calculate 40 to 60th percentiles and full range for each COMID
df_temp_stream <- df_temp |> 
  group_by(stream, yday) |> 
  summarise(
    mean = mean(temp),
    temp_40 = quantile(temp, probs = 0.4),
    temp_60 = quantile(temp, probs = 0.6),
    temp_min = min(temp),
    temp_max = max(temp), 
    .groups = "drop"
  )

# plot ribbom of 40-60th percentiles and range over yday
df_temp_stream |> 
  ggplot(aes(x = as.Date("2000-12-31") + yday)) +
  facet_rep_wrap(~stream, ncol = 2) +
  geom_ribbon(data = df_temp_stream, aes(ymin = temp_min, ymax = temp_max), fill = "grey") +
  geom_ribbon(data = df_temp_stream, aes(ymin = temp_40, ymax = temp_60), fill = "red") +
  geom_line(aes(y = mean), color = "black") + 
  scale_color_brewer(palette = "Accent") +
  scale_x_date(date_breaks = "1 month", date_labels = "%b") +
  labs(
    title = "Modeled thermal regimes (2001-2004) for MFSR tributaries",
    subtitle = "Black line = mean, Red ribbon = 40 - 60th percentiles, Grey ribbon = full range",
    x = "", 
    y = "Daily water<br>temperature (\u00b0C)",
    color = "Year"
  ) + 
  theme_bw() +
  theme(axis.title.y = ggtext::element_markdown())

# # calculate 40 to 60th percentiles and full range for each stream an year
# df_temp_stream_year <- df_temp |> 
#   group_by(year, stream, yday) |> 
#   summarise(
#     temp_40 = quantile(temp, probs = 0.4),
#     temp_60 = quantile(temp, probs = 0.6),
#     temp_min = min(temp),
#     temp_max = max(temp), 
#     .groups = "drop"
#   )
# 
# # plot ribbom of 40-60th percentiles and range over yday
# df_temp_stream_year |> 
#   ggplot(aes(x = as.Date("2000-12-31") + yday)) +
#   facet_rep_grid(cols = vars(year), rows = vars(stream)) +
#   geom_ribbon(data = df_temp_stream_year, aes(ymin = temp_min, ymax = temp_max), fill = "grey") +
#   geom_ribbon(data = df_temp_stream_year, aes(ymin = temp_40, ymax = temp_60), fill = "red") +
#   scale_color_brewer(palette = "Accent") +
#   scale_x_date(date_breaks = "1 month", date_labels = "%b") +
#   labs(
#     # title = glue::glue("Modeled thermal regime (2001-2004) at COMID {unique(df_temp$COMID)}"),
#     caption = "Red ribbom = 40-60th percentiles\nGrey ribbom = full range",
#     x = "", 
#     y = "Daily water<br>temperature (\u00b0C)",
#     color = "Year"
#   ) + 
#   theme_bw() +
#   theme(axis.title.y = ggtext::element_markdown())
```

##### Stream temperature metrics

We calculated metrics relative to a COMID a redd was constructed on and a redd completion date; before, after, and spanning the date. For example, temp_30_before is the average temperature for a COMID where a redd was constructed calculated over the previous 30 days. We did this for 30, 60, and 90 days. We also calculated a time invariant metric relative to a fixed date across all years that was chosen to represent an initial spawning window, e.g., August 1. The time invariant and after metrics were omitted from further consideration as preliminary data exploration showed weak if any relationship with spawn timing.

```{r}
# summarized temperature data (`out`), see (map_comid_temps.R)
load(here("data", "comid_temps.RData"))

temp_data <- out |>
  filter(period == "before" & duration %in% c(30, 60, 90)) |>
  pivot_wider(
    names_from = "duration", 
    values_from = avg_temp, 
    names_prefix = "temp_"
    ) |> 
  select(redd_id, COMID = comid, spawn_date, temp_30, temp_60, temp_90)

# summarized temp data
head(temp_data)
```

#### Discharge (streamflow)

Stream flow data were compiled from a single USGS Gage lower in the watershed (MF Salmon River at MF Lodge NR Yellow Pine ID - 13309220). Becuase flow data are not COMID- or stream-specific, it makes sense to think about and represent flow as an out-of-basin year effect that determines when adults make it back to the MFSR and initially onto the spawning grounds.

```{r}
# raw flow data (see flow_calculations.R)
df_flows <- read_csv("data/mfsr_flow.csv")

# get day of year and year
df_flows <- df_flows |> 
  select(date = Date, flow_cfs = Flow) |> 
  mutate(yday = yday(date), year = as_factor(year(date))) |> 
  mutate(flow_csm = flow_cfs * 0.028316846592) 
df_flows
```

##### Inter-annual variability

```{r}
p.flow.1 <- df_flows |> 
  ggplot(aes(x = as.Date("2000-12-31") + yday, y = flow_csm, color = year)) +
  geom_line() +
  scale_color_brewer(palette = "Dark2") +
  scale_x_date(date_breaks = "1 month", date_labels = "%b") +
  scale_y_continuous(limits = c(0,400), breaks = seq(0, 400, 50)) +
  labs(
    title = "Linear scale",
    x = "", 
    y = "Mean daily discharge (m<sup>3</sup> s<sup>-1</sup>)",
    color = "Year"
  ) + 
  theme_bw() + 
  theme(axis.title.y = ggtext::element_markdown()) 

p.flow.2 <- df_flows |> 
  ggplot(aes(x = as.Date("2000-12-31") + yday, y = flow_csm, color = year)) +
  geom_line() +
  scale_color_brewer(palette = "Dark2") +
  scale_x_date(date_breaks = "1 month", date_labels = "%b") +
  # scale_y_continuous(limits = c(0,400), breaks = seq(0, 400, 50)) +
  scale_y_log10() +
  labs(
    title = "Log scale",
    x = "", 
    y = "",
    # y = "Mean daily discharge (m<sup>3</sup> s<sup>-1</sup>)",
    color = "Year"
  ) + 
  theme_bw() + 
  theme(axis.title.y = ggtext::element_markdown()) 

# p.flow.1 + p.flow.2 + 
#   plot_layout(guides = "collect") + 
#   plot_annotation(title = "Measured discharge at MF Lodge, USGS Gage 13309220")

# calculate 40 to 60th percentiles and full range for each COMID
tmp <- df_flows |> 
  group_by(yday) |>
  summarise(
    mean = mean(flow_csm),
    flow_40 = quantile(flow_csm, probs = 0.4),
    flow_60 = quantile(flow_csm, probs = 0.6),
    flow_10 = quantile(flow_csm, probs = 0.1),
    flow_90 = quantile(flow_csm, probs = 0.9), 
    .groups = "drop"
  )

# plot ribbom of 40-60th percentiles and range over yday
p.flow.3 <- tmp |> 
  ggplot(aes(x = as.Date("2000-12-31") + yday)) +
  geom_ribbon(data = tmp, aes(ymin = flow_10, ymax = flow_90), fill = "grey") +
  geom_ribbon(data = tmp, aes(ymin = flow_40, ymax = flow_60), fill = "blue") +
  geom_line(aes(y = mean), color = "black") + 
  scale_color_brewer(palette = "Accent") +
  scale_x_date(date_breaks = "1 month", date_labels = "%b") +
  scale_y_log10() +
  labs(
    # title = "Measured discharge at MF Lodge, USGS Gage 13309220",
    subtitle = "Black line = mean, blue ribbon = 40 - 60th percentiles, Grey ribbon = full range",
    x = "", 
    y = "Log Daily discharge (m<sup>3</sup> s<sup>-1</sup>)",
    color = "Year"
  ) + 
  theme_bw() +
  theme(axis.title.y = ggtext::element_markdown())

(p.flow.1 + p.flow.2) / p.flow.3 + 
  plot_layout(guides = "collect") + 
  plot_annotation(title = "Measured discharge at MF Lodge, USGS Gage 13309220")
```

##### Flow metrics

We calculated flow metrics relative to a COMID a redd was constructed on and a redd completion date; before, after, and spanning the date. For example, temp_30_before is the average temperature for a COMID where a redd was constructed calculated over the previous 30 days. We did this for 30, 60, and 90 days. The spanning and after metrics were omitted from further consideration as preliminary data exploration showed weak if any relationship with spawn timing.

```{r}
# summarized flow data (see flow_calculations.R)
flow_data <- read_csv(here("data", "spawn_flows.csv"))
flow_data
```

#### Elevation and stream gradient (slope)

Elevation and stream slope data were available at the COMID (stream reach) scale from the NHD.

```{r}
# elevation and slope from NHD
df_elev_slope <- readRDS(here("data", "elevslope.rds")) |> 
  as_tibble() |> 
  mutate(mean_elevation = (MAXELEVSMO + MINELEVSMO) / 2 / 100) |> 
  select(COMID, slope = SLOPE, mean_elevation)
df_elev_slope
```

#### Combine datasets

```{r combine-data}

combined_data <- spawn_data |>
  left_join(temp_data |> select(-spawn_date), by = "redd_id") |>
  left_join(flow_data, by = "spawn_date") |> 
  left_join(df_elev_slope |> mutate(COMID = as.factor(COMID)), join_by(COMID)) |>
  mutate(
    yday = yday(date)
  )

combined_data <- combined_data |>
  left_join(temp_data, join_by(UNIQUE_ID == redd_id))

# add physical data to combined data and then filter
combined_data <- combined_data |>
  left_join(df_elev_slope |> mutate(COMID = as.factor(COMID)), join_by(COMID)) |>
  mutate(
    yday = yday(date)
  )

# # join with lgd data
# combined_data <- combined_data |>
#   left_join(lgd_chinook, join_by(year))
```

```{r model-data, echo=TRUE}
# make a df of just response and covariates
model_data <- combined_data |>
  filter(SLOPE < .2) |> # bad slope data
  select(
    yday, COMID, stream, year,
    flow_30, flow_60, flow_90,
    temp_30, temp_60, temp_90,
    SLOPE, mean_elevation
  )
glimpse(model_data)
```

## Descriptive stats and visualizations

### Response data

#### Variation in spawn timing

```{r plot-desc-spawn, echo=FALSE, fig.width=10, fig.height=8}
# historgram and density of spawn timing
p1 <- ggplot(spawn_data, aes(x = yday)) +
  geom_histogram(
    aes(y = after_stat(density)),
    bins = 30, fill = "gray70", color = "black") +
  geom_density(color = "black", size = 1.2) +
  geom_vline(
    aes(xintercept = mean(yday)),
    color = "black", linetype = "dashed", linewidth = 1.2) +
  # scale_x_continuous(limits = c(200, 270), breaks = seq(200, 270, 10)) +
  # lemon::coord_capped_cart(bottom='both', left = "both") +
  annotate(
    "text", x = 260, y = .06, hjust = 1, vjust = 1, size = 4.5,
    label = paste0
    (
      "mean = ", round(mean(spawn_data$yday), 2), "\n",
      "median = ", round(median(spawn_data$yday), 2), "\n",
      "min = ", round(min(spawn_data$yday), 2), "\n",
      "max = ", round(max(spawn_data$yday), 2), "\n",
      "var = ", round(var(spawn_data$yday), 2), "\n",
      "SD = ", round(sd(spawn_data$yday), 2)
    )
  ) +
  labs(
    title = "Histogram and Density of Spawn Dates",
    x = "Spawn Date (DOY)",
    y = "Density"
  ) +
  theme_custom()

# plot spawn date by stream
p2 <- ggplot(spawn_data, aes(x = stream, y = yday)) +
  geom_boxplot() +
  geom_jitter(aes(color = stream), size = 1.5, alpha = 0.1) +
  # lemon::coord_flex_cart(bottom=lemon::brackets_horisontal()) +
  labs(
    title = "Spawn Date by Stream",
    x = "Stream",
    y = "Spawn Date (DOY)"
  ) +
  theme_custom() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Plot spawn date by year
p3 <- ggplot(spawn_data, aes(x = year, y = yday)) +
  geom_boxplot() +
  geom_jitter(aes(color = year), size = 1.5, alpha = 0.1) +
  labs(
    title = "Spawn Date by Year",
    x = "Year",
    y = "Spawn Date (DOY)"
  ) +
  theme_custom() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# panel
p1 / (p2 + p3)
```

-   mean and median are equal, low SD
-   var \< mean (no overdispersion) data are right-skewed, lumpy/multimodal, and not symmetric at least
-   Poisson family is response is count of spawning events per day, Gaussian if model density as continuous

#### Spawn time variation by year and stream

```{r fig.width=8}
# labs <- spawn_data |> 
#   group_by(year, stream) |> 
#   tally()

p4 <- spawn_data |>
  ggplot(aes(x = year, y = yday, color = year)) +
  lemon::facet_rep_wrap(~stream) + 
  geom_boxplot() + 
  # geom_text(data = labs, aes(year, 210, label = n), vjust = 1) +
  scale_y_continuous(limits = c(200, 270), breaks = seq(200, 270, 20)) +
  theme_custom() + 
  labs(
    # title = "Spawn Date by Year and Stream",
    # subtitle = "(sample size below boxplot)", 
    x = "",
    y = "Spawn Date (DOY)"
  )
p4
```

#### Spawn time by COMID and stream

```{r}
spawn_data |> 
  ggplot(aes(x = COMID, y = yday, color = stream)) + 
  facet_wrap(~stream, scales = "free_x") +
  geom_boxplot() + 
  theme_custom() + 
  theme(axis.text.x = element_text(angle = 90, size = 8))
```

#### Spawn time distributions by stream

```{r plot-temp-dist-spawn, fig.height=10}
mfsr_by_site <- spawn_data |>
  group_by(stream, yday)

mfsr_all <- spawn_data |>
  summarise(
    median = median(yday),
    percentile_95 = quantile(yday, probs = 0.95),
    percentile_5 = quantile(yday, probs = 0.05)
  )

p5 <- plot <- spawn_data |>
  mutate(across(year, as.character)) |>
  group_by(stream, year) |>
  ggplot() +
  lemon::facet_rep_wrap(~stream, scales = "free_y", ncol = 2) +
  geom_vline(
    xintercept = mfsr_all$median, 
    color = "blue", 
    linetype = "dashed") +
  geom_vline(
    xintercept = c(mfsr_all$percentile_95, mfsr_all$percentile_5), 
    color = "purple", 
    linetype = "dashed") +
  geom_density(aes(x = yday, y = after_stat(count), fill = year), alpha = 0.5) +
  geom_density(data = mfsr_by_site, aes(x = yday, after_stat(count)), alpha = 0, linetype = "dashed") +
  scale_fill_brewer(palette = "Dark2", name = "Year") +
  labs(x = "Spawn Day of Year", y = "Count of redds") +
  theme_custom()
p5
```

#### Cumulative proportions of redds by stream

```{r plot-cum-props, fig.height=10}
# Proportional cumulative redds ------------------------------------------------
# spawn_data %>%
#   group_by(stream, yday) %>%
#   tally() %>%
#   group_by(stream) %>%
#   arrange(yday) %>%
#   mutate(cumulative = cumsum(n)) %>%
#   ggplot(aes(x = yday, y = cumulative, color = stream)) +
#   geom_line() +
#   labs(title = "Cumulative Redd Counts", y = "Cumulative Redds") +
#   theme_custom()


# Proportional cumulative redds by stream --------------------------------------
# For each year and stream, calculate the prop. cumulative number of redds
props <- spawn_data |> 
  select(year, stream, yday) |>
  group_by(year, stream, yday) |>
  add_count() |> 
  distinct() |> 
  group_by(year, stream) |>
  arrange(year, stream, yday) |>
  mutate(cum_redds = cumsum(n)) |> 
  mutate(cum_redds_p = cum_redds / max(cum_redds))

# Plot pro. cumsums
p6 <- props |> 
  ggplot(aes(x = yday, y = cum_redds_p, color = as.factor(year))) +
  lemon::facet_rep_wrap(~stream, ncol = 2, scales = "free_y") +
  geom_line(linewidth = 0.5) + 
  geom_point(size = 0.3) + 
  theme_custom() + 
  scale_y_continuous(limits = c(0,1), breaks = seq(0,1,0.5)) + 
  scale_color_brewer(palette = "Dark2") + 
  labs(
    x = "Day of Year",
    y = "Proportional Cumulative Redds",
    color = ""
  )
p6
```

## Bivariate relationships with covariates

```{r plot-covars, fig.height=12}
plot_covariate <- function(data, covariate) {
  ggplot(data, aes_string(x = covariate, y = "yday")) +
    geom_point() +
    geom_smooth(method = "lm") +
    labs(x = covariate, y = "DOY") +
    theme_custom()
}
covariates <- c("temp_30", "flow_30", "temp_60", "flow_60", "temp_90", "flow_90", "SLOPE", "mean_elevation")
plots <- map(covariates, ~ plot_covariate(model_data, .x))
gridExtra::grid.arrange(grobs = plots, ncol = 2)
```

-   temp_30 = no relationship, drop
-   temp_60 = good non-linear, drop for temp_90?
-   temp_90 = better non-linear
-   flow_30 and flow_60 = similar decaying exponential
-   flow_90 = inflections, interesting grouping really spreads out, year effect
-   SLOPE = no relationship, drop
-   mean_elevation = slightly negative linear?

## Check for colinearity

```{r plot-colinearity, echo=TRUE, fig.width=10, fig.height=10}
model_data |> 
  select(temp_30, temp_60, temp_90, flow_30, flow_60, flow_90, mean_elevation) |> 
  GGally::ggpairs()
```

-   There is strong colinearity among temp variable. Retaining temp_90 as it has the strongest relationship.
-   flow_30 and flow_60 are highly correlated with flow_90. We will keep flow_90 as it has the strongest relationship.
-   elevation good to keep

Check VIFs with and without `flow_30` and `flow_60`:

```{r vifs, echo=TRUE}
car::vif(lm(yday ~ flow_30 + flow_60 + flow_90 + temp_90 + mean_elevation + stream + year, data = model_data))
car::vif(lm(yday ~ flow_90 + temp_90 + mean_elevation + stream + year, data = model_data))
```

-   more reason to drop flow 30 and 90

## Closer look at covariates

### Temp_90

```{r plot-temp_90, fig.height=8}
(ggplot(model_data, aes(x = temp_90, y = yday, color = year)) +
  geom_point() +
  geom_smooth(method = "lm") +
  theme_custom() + 
  theme(legend.position = "right")) /

(ggplot(model_data, aes(x = temp_90, y = yday, color = stream)) +
  geom_point() +
  geom_smooth(method = "lm") +
  theme_custom() + 
  theme(legend.position = "right")) +
  plot_annotation(title = "Spawn Timing vs. 90-day mean temperature pre spawn")
```

-   clear positive relationship, certainly some non-linearity
-   stream- and year-level variation (interactions)

Check simple models for temp to examine functional structure:

```{r temp_90-mods, echo=TRUE}
m1 <- lm(yday ~ temp_90, data = model_data)
m2 <- lm(yday ~ temp_90 * stream, data = model_data)
m3 <- lm(yday ~ temp_90 * stream + poly(temp_90, 2), data = model_data)
m4 <- lm(yday ~ poly(temp_90, 2), data = model_data)
m5 <- gam(yday ~ s(temp_90, k = 5), data = model_data, method = "REML")
m6 <- gam(yday ~ s(temp_90, by = stream, k = 5), data = model_data, method = "REML")

AIC(m1, m2, m3, m4, m5, m6) |> 
  arrange(AIC) |> 
  mutate(delta = AIC - min(AIC)) |>
  kableExtra::kbl() |> 
  kableExtra::kable_styling("striped", full_width = F)

m11 <- lm(yday ~ temp_90, data = model_data)
m22 <- lm(yday ~ temp_90 * year, data = model_data)
m33 <- lm(yday ~ temp_90 * year + poly(temp_90, 2), data = model_data)
m44 <- lm(yday ~ poly(temp_90, 2), data = model_data)
m55 <- gam(yday ~ s(temp_90, k = 5), data = model_data, method = "REML")
m66 <- gam(yday ~ s(temp_90, by = year, k = 5), data = model_data, method = "REML")

AIC(m11, m22, m33, m44, m55, m66) |> 
  arrange(AIC) |> 
  mutate(delta = AIC - min(AIC)) |>
  kableExtra::kbl() |> 
  kableExtra::kable_styling("striped", full_width = F)
```

-   linear model is bad, quadratic is better, but GAM is best based on AIC
-   GAM is overfitting, and the quadratic model is flexible enough to capture the non-linearity

```{r temp_90_preds}
# Prediction
pred_data_stream <- model_data %>%
  group_by(stream) %>%
  summarize(min = min(temp_90), max = max(temp_90)) %>%
  rowwise() %>%
  do(data.frame(stream = .$stream,
                temp_90 = seq(.$min, .$max, length.out = 100))) %>%
  ungroup()

pred_data_stream$yday_pred_m3 <- predict(m3, newdata = pred_data_stream)
pred_data_stream$yday_pred_m6 <- predict(m6, newdata = pred_data_stream)

pred_data_year <- model_data %>%
  group_by(year) %>%
  summarize(min = min(temp_90), max = max(temp_90)) %>%
  rowwise() %>%
  do(data.frame(year = .$year,
                temp_90 = seq(.$min, .$max, length.out = 100))) %>%
  ungroup()

pred_data_year$yday_pred_m3 <- predict(m33, newdata = pred_data_year)
pred_data_year$yday_pred_m6 <- predict(m66, newdata = pred_data_year)
```

```{r}
pt901 <- model_data |> 
  ggplot(aes(x = temp_90, y = yday, color = stream)) +
  facet_rep_wrap(~stream) +
  geom_point(alpha = 0.3) +
  # geom_smooth(method = "lm", formula = y ~ x, se = FALSE, color = "grey1") +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), se = FALSE, color = "grey50") +
  # geom_smooth(method = "gam", formula = y ~ s(x, k = 5), method.args = list(method = "REML"), se = FALSE, color = "grey90") +
  geom_line(data = pred_data_stream, aes(x = temp_90, y = yday_pred_m3), size = 1.2) +
  # geom_line(data = pred_data_stream, aes(x = temp_90, y = yday_pred_m6), size = 1.2) +
  theme_custom() +
  labs(title = "yday ~ temp_90 * stream + poly(temp_90, 2)", 
       subtitle = "",
       y = "Day of Year",
       x = "Temp (90-day mean pre-spawn)")

pt902 <- model_data |> 
  ggplot(aes(x = temp_90, y = yday, color = stream)) +
  facet_rep_wrap(~stream) +
  geom_point(alpha = 0.3) +
  # geom_smooth(method = "lm", formula = y ~ x, se = FALSE, color = "grey1") +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), se = FALSE, color = "grey50") +
  # geom_smooth(method = "gam", formula = y ~ s(x, k = 5), method.args = list(method = "REML"), se = FALSE, color = "grey90") +
  # geom_line(data = pred_data_stream, aes(x = temp_90, y = yday_pred_m3), size = 1.2) +
  geom_line(data = pred_data_stream, aes(x = temp_90, y = yday_pred_m6), size = 1.2) +
  theme_custom() +
  labs(title = "yday ~ s(temp_90, by = stream, k = 5)", 
       subtitle = "",
       y = "Day of Year",
       x = "Temp (90-day mean pre-spawn)")

pt903 <- model_data |> 
  ggplot(aes(x = temp_90, y = yday, color = year)) +
  facet_rep_wrap(~year) +
  geom_point(alpha = 0.3) +
  # geom_smooth(method = "lm", formula = y ~ x, se = FALSE, color = "grey1") +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), se = FALSE, color = "grey50") +
  # geom_smooth(method = "gam", formula = y ~ s(x, k = 5), method.args = list(method = "REML"), se = FALSE, color = "grey90") +
  geom_line(data = pred_data_year, aes(x = temp_90, y = yday_pred_m3), size = 1.2) +
  # geom_line(data = pred_data_year, aes(x = temp_90, y = yday_pred_m6), size = 1.2) +
  theme_custom() +
  labs(title = "yday ~ temp_90 * year + poly(temp_90, 2)", 
       subtitle = "",
       y = "Day of Year",
       x = "Temp (90-day mean pre-spawn)")

pt904 <- model_data |> 
  ggplot(aes(x = temp_90, y = yday, color = year)) +
  facet_rep_wrap(~year) +
  geom_point(alpha = 0.3) +
  # geom_smooth(method = "lm", formula = y ~ x, se = FALSE, color = "grey1") +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), se = FALSE, color = "grey50") +
  # geom_smooth(method = "gam", formula = y ~ s(x, k = 5), method.args = list(method = "REML"), se = FALSE, color = "grey90") +
  # geom_line(data = pred_data_year, aes(x = temp_90, y = yday_pred_m3), size = 1.2) +
  geom_line(data = pred_data_year, aes(x = temp_90, y = yday_pred_m6), size = 1.2) +
  theme_custom() +
  labs(title = "yday ~ s(temp_90, by = year, k = 5)", 
       subtitle = "",
       y = "Day of Year",
       x = "Temp (90-day mean pre-spawn)")
```

```{r}
pt901
pt902
pt903
pt904
```

### Flow_90

```{r plot-flow_90, fig.height=8}
(ggplot(model_data, aes(x = flow_90, y = yday, color = year)) +
  geom_point() +
  geom_smooth(method = "lm") +
  theme_custom() + 
  theme(legend.position = "right")) /

(ggplot(model_data, aes(x = flow_90, y = yday, color = stream)) +
  geom_point() +
  geom_smooth(method = "lm") +
  theme_custom() + 
  theme(legend.position = "right")) + 
  plot_annotation(title = "Spawn Timing vs. 90-day mean flow pre spawn", theme = theme_custom())
```

-   clear negative relationship, higher 90-day mean flows are associated with earlier spawn timing
-   relationship differs by year: 2003 linear but flattening or non-linear at higher flows
-   suggest different slopes or curves across years (year specific responses, but just intercepts)
-   stream-level variation as well, different intercepts and slopes
-   this is really a year effect with variation by stream and comid (local)

Check simple models for flow to examine functional structure:

```{r flow_90_mods, echo=TRUE}
# compare linear, quadriatic, and gam model
m1 <- lm(yday ~ flow_90, data = model_data)
m2 <- lm(yday ~ flow_90 * year, data = model_data)
m3 <- lm(yday ~ flow_90 * year + poly(flow_90, 2), data = model_data)
m4 <- lm(yday ~ poly(flow_90, 2), data = model_data)
m5 <- gam(yday ~ s(flow_90, k = 5), data = model_data, method = "REML")
m6 <- gam(yday ~ s(flow_90, by = year, k = 5), data = model_data, method = "REML")

AIC(m1, m2, m3, m4, m5, m6) |> 
  arrange(AIC) |> 
  kableExtra::kbl() |> 
  kableExtra::kable_styling("striped", full_width = F) |> 
  kableExtra::add_header_above(c(" " = 1, "AIC" = 2))

# sjPlot::tab_model(m1, m2, m3, m4, m5, m6)
# summary(m2)

# prediction grid
pred_data <- model_data %>%
  group_by(year) %>%
  summarize(min_flow = min(flow_90), max_flow = max(flow_90)) %>%
  rowwise() %>%
  do(data.frame(year = .$year,
                flow_90 = seq(.$min_flow, .$max_flow, length.out = 100))) %>%
  ungroup()

# Predict
pred_data$yday_pred_m2 <- predict(m2, newdata = pred_data)
pred_data$yday_pred_m3 <- predict(m3, newdata = pred_data)
pred_data$yday_pred_m6 <- predict(m6, newdata = pred_data)

model_data |> 
  ggplot(aes(x = flow_90, y = yday, color = year)) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE, color = "grey1") +
  geom_smooth(method = "lm", formula = y ~ poly(x, 2), se = FALSE, color = "grey50") +
  geom_smooth(method = "gam", formula = y ~ s(x, k = 5), method.args = list(method = "REML"), se = FALSE, color = "grey90") +
  geom_line(data = pred_data, aes(x = flow_90, y = yday_pred_m2), size = 1.2) +
  geom_line(data = pred_data, aes(x = flow_90, y = yday_pred_m3), size = 1.2) +
  geom_line(data = pred_data, aes(x = flow_90, y = yday_pred_m6), size = 1.2) +
  theme_custom() +
  labs(title = "Model fits", 
       subtitle = "",
       y = "Day of Year",
       x = "Flow (90-day mean pre-spawn)")
```

-   linear model is bad, quadratic is better, but GAM is best based on AIC
-   GAM is defintely overfitting becuase each year has a narrow flow range, only 2003 has high flows
-   poly fit with year intereaction is best non-GAM fit, but still probably overfitted

#### To include or not to include flow_90?

Including flow_90 could introduce spurious precision and possibly overfitting. Why flow_90 might be problematic:

1.  Not spatially resolved

-   We are modeling spawn timing at the redd level (COMID/stream)
-   But flow_90 is calculated from a single downstream gauge, and applied to all redds
-   This assumes flow conditions are identical across all sites, which is rarely true in a branching stream network
-   Including it gives the illusion of spatially resolved variation that isnât there

2.  Likely correlated with year

-   Since flow_90 varies mostly across years, (albeit slightly with streams), it is strongly confounded with year
-   Any flow-related signal is probably already captured by your year fixed effect
-   Including both flow_90 and year risks collinearity, and may produce misleading inferences

3.  Spawn-time aligned flow â  experienced flow

-   While flow_90 is aligned to each reddâs spawn date, it still reflects a lower-basin gauge, not the actual hydrologic conditions experienced at the redd site
-   So it might be precisely wrong â aligned in time but irrelevant in space

**Bottom Line**: Unless we have site-specific or spatially disaggregated flow data, flow_90 is probably not a valid covariate for redd-level models.

Including it may:

-   Overfit due to noise or pseudo-replication
-   Complicate interpretation (e.g., why one stream "responds" to flows measured elsewhere?)
-   Mask true year or site effects

**Recommendation**: Drop flow_90 from model (or at most, keep it as a year-level covariate if you summarize it to a single annual value for all observations)

Although we initially considered including 90-day mean streamflow (`flow_90`) as a predictor of spawn timing, this variable was ultimately excluded due to concerns about ecological validity and model overfitting. Streamflow data were derived from a single downstream USGS gauge and did not capture spatial variation across the study streams or reaches. Moreover, because flow_90 was closely aligned with year, it introduced strong collinearity with the year effect and risked attributing site-level variation to flow patterns not actually experienced by individual redds. As such, we excluded flow_90 to avoid misleading inference.

## Scale and final dataset

Final dataset includes:

-   response: spawn time (doy), continuous
-   grouping variables: comid, stream, year (but not using COMID due to sparse data)
-   temp_90, flow_90, elevation

```{r final-dataset, echo=TRUE}
# select variables and standardize continuous covariates
scale2 <- function(x, na.rm = FALSE) (x - mean(x, na.rm = na.rm)) / sd(x, na.rm)

# model_data_final <- model_data |>
#   select(yday, COMID, stream, year, temp_90, mean_elevation) 

model_data_final <- model_data |>
  select(yday, COMID, stream, year, temp_90, mean_elevation) |>
  mutate(across(c("temp_90", "mean_elevation"), scale2))
```

## Model specification

### Fixed and random effects

We should only include a grouping variable as both fixef and ranef when you want to model differenct aspects of the effect. E.g., stream as fixed to compared average effects by stream, but as ranefs to account for non-independence of obs within each stream but not to compare average effects. Include as both when you want population-level estimates AND when you expect stream-level random variation around those means. Do not include both when intercepts are redundant (\~ stream + (1\| stream)), or too few levels for the random effect to be estimated (e.g., \<5 levels).

| Variable | Fixed? | Random? | Why |
|------------------|------------------|------------------|------------------|
| COMID | No | Yes (but must check data availability among levels; likely sparse) | Not estimating individual COMID effects, just accounting for correlation. |
| Stream | Yes | Maybe (only if random slope or complex structure) | May want to estimate differences and account for grouping. |
| Year | Yes (comparing years) | Maybe (account for inter-annual variability) | Use one or the other depending on goal. |

In this case, it makes sense to include year as fixed because:

-   only has 4 levels - so a ranef would estimate variance poorly and shrink aggressively
-   year captures unmeasured inter annual variability (snow pack, flow, temp anomalies all wrapped in)
-   we want to compare among years given we only have 4 years of data, hard to extrapolate

### Overfitting

On our first couple passes, we used models with renefs, but were observing strong overfitting. Hereâs whatâs likely going wrong with the mixed-effects model:

High AIC-based model performance but stream-level predictions far from observed data , so random effects absorbing noise or overfitting sparse groups. Random intercepts for COMID dominate variance becuase many COMIDs have only 1 observation â intercepts become noise. Unequal data across years and streams means random intercepts get misled by imbalance, especially for sparse years (like 2005). Random slopes and interactions fail to improve fit because not enough data per group to support slope variation.

A simple lm may be better here because it treats stream and year as explicit, estimable fixed effects, which gives you real, interpretable estimates for group means. It doesnât try to âguessâ partial-pooling intercepts or slopes where data are lacking. The model becomes transparent â predictions reflect whatâs in the data, not what the model infers from structure.

Let's interrogate the grouping structure within the data to make a final decision.

### Grouping structure of data

#### COMIDs per stream, and observations per COMID

```{r}
# number of comids per stream
spawn_data |> 
  distinct(stream, COMID) |> 
  count(stream, name = "n_COMIDs") |> 
  arrange(desc(n_COMIDs)) |> 
  kableExtra::kbl(caption = "Number of comids per stream") |>
  kableExtra::kable_styling("striped", full_width = TRUE) 

# How many COMIDs have <5 observations?
n_sparse_COMIDS_5 <- spawn_data |> 
  count(COMID, name = "n_redds") |> 
  filter(n_redds < 5) |> 
  nrow()
n_sparse_COMIDS_2 <- spawn_data |> 
  count(COMID, name = "n_redds") |> 
  filter(n_redds <= 2) |> 
  nrow()

# what percent of comids have <= 1 obervation?
# spawn_data |> 
#   count(COMID, name = "n_redds") |> 
#   filter(n_redds <= 1) |> 
#   nrow() / length(unique(spawn_data$COMID)) * 100
# 
# spawn_data |> 
#   count(COMID, name = "n_redds") |> 
#   filter(n_redds <= 2) |> 
#   nrow() / length(unique(spawn_data$COMID)) * 100
# 
# spawn_data |> 
#   count(COMID, name = "n_redds") |> 
#   filter(n_redds <= 5) |> 
#   nrow() / length(unique(spawn_data$COMID)) * 100

# number of observations per COMID
spawn_data |> 
  count(COMID, name = "n_redds") |> 
  arrange(n_redds) |> 
  ggplot(aes(n_redds)) +
  geom_bar() + 
  scale_y_continuous(breaks = seq(0,10,1)) + 
  labs(title = "Number of obervations (redds) per COMID") + 
  theme_custom()
```

There are at least 6 COMIDs per stream, and the number of observations per COMID is highly variable. The histogram shows that most COMIDs have 1-2 observations, but some have many more. `r n_sparse_COMIDS_5` COMIDs have fewer than 5 observations.

#### Summary

Are the enough COMIDs per stream to consider stream/COMID nested random effects? No.

Are groups well sampled? (Do most COMIDs have \>1-2 redds?) No. 23 COMIDs have \<5 redds (25%), 13 have \<= 2. (12.5%) With \<5 obs/level, variance estimates become unstable -\> overfit and absorb noise (low AIC / high R2) -\> singular fits.

Are year or stream-level random effects justifiable? We want to compare streams and years in this dataset, not generalize beyond them, so we should use fixed effects. Further, stream are known, of interest, and were not randomly sampled. Including (1 \| stream) would be statistically redundant (stream intercepts would be double-modeled) and would lead to misleading AIC comparisons.

Random slopes?. The needs multiple obs per group across a range of slope variable (temp_90), enough replication to estimate variation in slopes, not just intercepts. Need \~8+ obs per group spread across the covariate. We could do this for stream or year. Prob not.

So, we should use a simple linear model with no random effects. This allows for interpretable results, no overfitting from random effects, and is a reasonable approach given the design.

If we did try (1 \| COMID), expect singularity, low variance estimates for COMID, and predictions will likley miss the groups means.

## Model fitting and comparison

### Evaluate COMID as random intercept

```{r}
# Baseline fixed-effect model
m_fixed <- lm(yday ~ temp_90 + stream + year, data = model_data_final)

# Mixed-effect model with random intercept for COMID
m_rand <- lmer(yday ~ temp_90 + stream + year + (1 | COMID), data = model_data_final, REML = FALSE)

AIC(m_fixed, m_rand) |> 
  arrange(AIC) |> 
  mutate(delta = AIC - min(AIC)) 
# summary(m_rand)  # Check variance estimate for COMID
```

Does adding (1\|COMID) improve it without overfiitg? Improves AIC by \>2700. Is the variance explained by COMID non-zero and meaningful? Variance is 60 and likely meaninful. But, is it overfitting? Yes, the model is overfitting. The AIC is much lower, but the predictions are not close to the observed data (Not shown).

### Final candidate covariates and interactions

-   temp_90: 90-day mean temperature
-   mean_elevation: mean elevation of the stream reach
-   stream: stream name
-   year: year of observation

| Interaction | Description | Possible Interpretation |
|------------------|------------------------|------------------------------|
| `temp_90 Ã stream` | Temperature effects on spawn timing vary across streams | Some streams may be more thermally sensitive (e.g., due to groundwater, shading, etc.) |
| `temp_90 Ã year` | Interannual differences in how temperature affects spawn timing | Annual climate conditions (e.g., snowmelt timing, baseflow) modify temp-timing response |
| `stream Ã year` | Stream-specific interannual variation | Some streams respond more strongly to wet/dry or hot/cool years |
| `mean_elevation Ã stream` | Elevation effects on timing vary by stream | Elevation proxies snowpack or gradient, which may matter differently by stream |
| `mean_elevation Ã year` | Elevation effects change across years | Snowmelt timing shifts may be more impactful in some years |
| `temp_90 Ã mean_elevation` | Thermal effects depend on elevation | High-elevation streams may respond more strongly or weakly to the same temp range |

The most plausible core interactions to include a prior are: - `temp_90 Ã stream` - `temp_90 Ã year`

Others like `stream x year` are data hungry and may overfit without strong replication. Interactions with `mean_elevation` does not make much sense.

We used AIC-based model selection to identify the best-supported linear model that included temp_90, mean_elevation, stream, year, and all two-way interactions. This model outperformed all simpler alternatives by a large AIC margin. We then tested an alternative model including a raw quadratic term (I(temp_90\^2)) to account for potential nonlinearity in the temperatureâspawn timing relationship. Model performance was evaluated using AIC and visual assessment of stream- and year-specific predictions.

### Simple LM

First we'll fit simple linear models to get a sense of the data and the relationships. Adding new interactions each time.

```{r echo=TRUE}
# m0 <- lmer(yday ~ temp_90 + stream + year + (1 | COMID), data = model_data_final)
m1 <- lm(yday ~ temp_90 + mean_elevation + stream + year, data = model_data_final)
m2 <- lm(yday ~ temp_90 * stream + temp_90 + mean_elevation + stream + year, data = model_data_final)
m3 <- lm(yday ~ temp_90 * stream + temp_90 * year + temp_90 + mean_elevation + stream + year, data = model_data_final)
m4 <- lm(yday ~ temp_90 * stream + temp_90 * year + stream * year + temp_90 + mean_elevation + stream + year, data = model_data_final)

AIC(m1, m2, m3, m4) |> 
  arrange(AIC) |> 
  mutate(delta = AIC - min(AIC)) 
```

Full interaction (m4) is best. We will now compare all possible combinations of the interactions, except stream x year.

### Dredge

```{r dredge, echo=TRUE, message=FALSE, warning=FALSE, results='hide'}
# global_model <- lm(yday ~ temp_90 * stream + temp_90 * year + stream * year + temp_90 + mean_elevation + stream + year, data = model_data_final)
global_model <- lm(yday ~ temp_90 * stream + temp_90 * year + temp_90 + stream + year + mean_elevation, data = model_data_final)

# Run dredge
options(na.action = "na.fail")  # Required for dredge
model_set <- dredge(global_model, trace = 1, rank = "AIC")

model_set
```

Model 64 with all 2-way interactions (save stream x year) is the best supported model based on AIC.

**NOTE** ELEVATION IS THE ISSUE CAUSING OFFSETS!!!! The best fitting model without elevation in the full model with all 2-way interactions. When plotting predictions using the model without elevation, the linear offsets are no more. This makes sense because the estimated coefficients for models with elevation are positive, which does not align with the observed data:

```{r echo=TRUE}
final_model <- get.models(model_set, 1)[[1]]
tmp <- ggeffects::ggpredict(final_model, terms = c("mean_elevation"))

ggplot(tmp, aes(x = x, y = predicted)) +
  geom_line(size = 1.1) +
  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = 0.2, color = NA) +
  geom_point(data = model_data_final, aes(x = mean_elevation, y = yday), size = .5) + 
  theme_custom() + 
  labs(title = "Elevation effect on spawn timing",
       subtitle = "Note the strong mismatch between predicted trend and observed data",
       x = "Mean Elevation (m)", y = "Spawn Day of Year") 
```

So we will select the best fitting model without elevation (model 127; AIC rank = 6)

## Diagnostics

```{r, echo=TRUE}
final_model <- get.models(model_set, 4)[[1]]
```

```{r}
# summary(final_model)
par(mfrow = c(2,2))
plot(final_model)
par(mfrow = c(1,1))
```

## Predictions

```{r fig.height=10}
pred_stream_temp <- ggeffects::ggpredict(final_model, terms = c("temp_90", "stream"))

# ggplot(pred_stream_temp, aes(x = x, y = predicted, color = group)) +
#   facet_rep_wrap(~group) +
#   geom_line(size = 1.1) +
#   geom_ribbon(aes(ymin = conf.low, ymax = conf.high, fill = group), alpha = 0.2, color = NA) +
#   geom_point(data = model_data_final, aes(x = temp_90, y = yday), color = "grey", size = .5) +
#   labs(title = "",
#        x = "90-day Mean Temp", y = "Spawn Day of Year", color = "Stream", fill = "Stream") +
#   theme_custom() +
#   theme(legend.position = "right") +
#   scale_color_manual(values = c("#E41A1C", "#377EB8", "#4DAF4A", "#FF7F00", "#FFFF33", "#A65628", "#999999", "#F781BF")) +
#   scale_fill_manual(values = c("#E41A1C", "#377EB8", "#4DAF4A", "#FF7F00", "#FFFF33", "#A65628", "#999999", "#F781BF"))

p20 <- ggplot(pred_stream_temp, aes(x = x, y = predicted, color = group)) +
  facet_rep_wrap(~group) +
  geom_line(size = 1.1) +
  geom_point(data = model_data_final, aes(x = temp_90, y = yday), color = "grey", size = .5) +
  geom_ribbon(aes(ymin = conf.low, ymax = conf.high, fill = group), alpha = 0.2, color = NA) +
  labs(title = "",
       x = "90-day Mean Temp", y = "Spawn Day of Year", color = "Stream", fill = "Stream") +
  theme_custom() +
  theme(legend.position = "right") +
  scale_color_manual(values = c("#E41A1C", "#377EB8", "#4DAF4A", "#FF7F00", "#FFFF33", "#A65628", "#999999", "#F781BF")) + 
  scale_fill_manual(values = c("#E41A1C", "#377EB8", "#4DAF4A", "#FF7F00", "#FFFF33", "#A65628", "#999999", "#F781BF")) 

pred_stream_temp <- ggeffects::ggpredict(final_model, terms = c("temp_90", "year"))

p21 <- ggplot(pred_stream_temp, aes(x = x, y = predicted, color = group)) +
  geom_line(size = 1.1) +
  geom_ribbon(aes(ymin = conf.low, ymax = conf.high, fill = group), alpha = 0.2, color = NA) +
  geom_point(data = model_data_final, aes(x = temp_90, y = yday, color = year), size = .5) +
  labs(title = "",
       x = "90-day Mean Temp", y = "Spawn Day of Year", color = "Stream", fill = "Stream") +
  theme_custom() +
  theme(legend.position = "right") +
  scale_color_manual(values = c("#E41A1C", "#377EB8", "#4DAF4A", "#FF7F00", "#FFFF33", "#A65628", "#999999", "#F781BF")) + 
  scale_fill_manual(values = c("#E41A1C", "#377EB8", "#4DAF4A", "#FF7F00", "#FFFF33", "#A65628", "#999999", "#F781BF")) 

p20 / p21 + plot_layout(ncol = 1) + plot_annotation(title = "Predicted vs Observed Spawn Timing", theme = theme_custom())
```

-   Some stream-specific fits still under perform, especially at extremes
-   Year-specific predictions are systematically low (in both linear and poly models)
-   The orthogonal poly(temp_90, 2) didn't resolve this and may be too constrained
-   Raw quadratic (I(temp_90\^2)) might help fine-tune curvature per stream or year

## Quadratic model

Next we will fit a new best + quadratic model.

```{r}
lm_poly <- lm(yday ~ temp_90 * stream + temp_90 * year + I(temp_90^2) + stream + year, data = model_data_final)
AIC(final_model, lm_poly) |> arrange(AIC) |> mutate(delta = AIC - min(AIC))
# summary(lm_poly)
```

The poly model improves AIC by \~210, major improvement. So the curvature is helping.

```{r fig.height=10}
pred_stream_temp <- ggeffects::ggpredict(lm_poly, terms = c("temp_90", "stream"))

p22 <- ggplot(pred_stream_temp, aes(x = x, y = predicted, color = group)) +
  facet_rep_wrap(~group) +
  geom_line(size = 1.1) +
  geom_point(data = model_data_final, aes(x = temp_90, y = yday), color = "grey", size = .5) +
  geom_ribbon(aes(ymin = conf.low, ymax = conf.high, fill = group), alpha = 0.2, color = NA) +
  # geom_point(data = model_data_final, aes(x = temp_90, y = yday, color = stream), size = .5) +
  labs(title = "",
       x = "90-day Mean Temp", y = "Spawn Day of Year", color = "Stream", fill = "Stream") +
  theme_custom() +
  theme(legend.position = "right") +
  scale_color_manual(values = c("#E41A1C", "#377EB8", "#4DAF4A", "#FF7F00", "#FFFF33", "#A65628", "#999999", "#F781BF")) +
  scale_fill_manual(values = c("#E41A1C", "#377EB8", "#4DAF4A", "#FF7F00", "#FFFF33", "#A65628", "#999999", "#F781BF")) 

pred_stream_temp <- ggeffects::ggpredict(lm_poly, terms = c("temp_90", "year"))

p23 <- ggplot(pred_stream_temp, aes(x = x, y = predicted, color = group)) +
  geom_line(size = 1.1) +
  geom_ribbon(aes(ymin = conf.low, ymax = conf.high, fill = group), alpha = 0.2, color = NA) +
  geom_point(data = model_data_final, aes(x = temp_90, y = yday, color = year), size = .5) +
  labs(title = "",
       x = "90-day Mean Temp", y = "Spawn Day of Year", color = "Stream", fill = "Stream") +
  theme_custom() +
  theme(legend.position = "right") +
  scale_color_manual(values = c("#E41A1C", "#377EB8", "#4DAF4A", "#FF7F00", "#FFFF33", "#A65628", "#999999", "#F781BF")) + 
  scale_fill_manual(values = c("#E41A1C", "#377EB8", "#4DAF4A", "#FF7F00", "#FFFF33", "#A65628", "#999999", "#F781BF")) 

p22 / p23 + plot_layout(ncol = 1) + plot_annotation(title = "Predicted vs Observed Spawn Timing", theme = theme_custom())
```

-   The quadratic model fits the data much better, especially at the extremes
-   The stream-specific fits are much better, but the year-specific fits are still systematically low (NOT ANY MORE - removed elevation)

### Compare linear and quadratic model plots

```{r fig.height=10}
# p20 + p21 + p22 + p23 + plot_layout(ncol = 2) + 
#   plot_annotation(title = "Predicted vs Observed Spawn Timing", 
#                   subtitle = "Comparing Linear and Quadratic Models",
#                   theme = theme_custom())
```

```{r fig.height=8}
# Linear model predictions
pred_linear <- ggeffects::ggpredict(final_model, terms = c("temp_90", "stream"))

# Quadratic model predictions
pred_quad <- ggeffects::ggpredict(lm_poly, terms = c("temp_90", "stream"))


# Combine predictions
pred_linear$model <- "Linear"
pred_quad$model <- "Quadratic"
pred_combined <- rbind(pred_linear, pred_quad)

# Merge stream colors from observed data if needed
ggplot() +
  geom_point(data = model_data_final, aes(x = temp_90, y = yday), color = "grey", alpha = 0.3, size = 0.7) +
  # geom_point(data = model_data_final, aes(x = temp_90, y = yday, color = stream), alpha = 0.3, size = 0.7) +
  geom_line(data = pred_combined, aes(x = x, y = predicted, color = group, linetype = model), size = 1.1, alpha = 0.7) +
  lemon::facet_rep_wrap(~group) +
  labs(title = "Stream-Specific Predicted vs Observed Spawn Timing",
       subtitle = "Comparing Linear and Quadratic Models",
       x = "90-day Mean Temp", y = "Spawn Day of Year",
       color = "Stream", linetype = "Model") +
  theme_custom() +
  scale_color_manual(values = c("#E41A1C", "#377EB8", "#4DAF4A", "#FF7F00", "#FFFF33", "#A65628", "#999999", "#F781BF")) + 
  scale_fill_manual(values = c("#E41A1C", "#377EB8", "#4DAF4A", "#FF7F00", "#FFFF33", "#A65628", "#999999", "#F781BF")) 

```

-   Dashed vs solid lines show differences between models
-   Improved fit near the tails or mid-range = quadratic model success

## Model fit comparison

### Calculate RMSE

```{r rmse, echo=TRUE}
# get preds for each model
model_data_final$pred_linear <- predict(final_model, newdata = model_data_final)
model_data_final$pred_quad   <- predict(lm_poly, newdata = model_data_final)

# compute error metrics by stream and year
model_error_summary <- model_data_final %>%
  mutate(error_linear = abs(yday - pred_linear),
         error_quad   = abs(yday - pred_quad)) %>%
  group_by(stream, year) %>%
  summarize(
    n = n(),
    MAE_linear = mean(error_linear),
    MAE_quad   = mean(error_quad),
    RMSE_linear = sqrt(mean((yday - pred_linear)^2)),
    RMSE_quad   = sqrt(mean((yday - pred_quad)^2)),
    .groups = "drop"
  )

# Long format
model_error_long <- model_error_summary %>%
  pivot_longer(cols = starts_with("RMSE"), names_to = "model", values_to = "RMSE") %>%
  mutate(model = ifelse(model == "RMSE_linear", "Linear", "Quadratic"))
```

### Stream level RMSE comparison

```{r}
# Stream level RMSE comparison
ggplot(model_error_long, aes(x = stream, y = RMSE, fill = model)) +
  geom_col(position = "dodge") +
  labs(title = "Model RMSE by Stream",
       y = "Root Mean Squared Error",
       x = "Stream") +
  theme_minimal()
```

### RMSE difference by stream

```{r}
model_error_summary %>%
  mutate(delta_RMSE = RMSE_linear - RMSE_quad) %>%
  ggplot(aes(x = reorder(stream, delta_RMSE), y = delta_RMSE, fill = delta_RMSE > 0)) +
  geom_col(show.legend = FALSE) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(title = "ÎRMSE by Stream (Linear - Quadratic)",
       x = "Stream", y = "RMSE Improvement from Quadratic", 
       subtitle = "(+) quadratic is better, (-) linear is better") +
  scale_fill_manual(values = c("firebrick", "steelblue")) +
  theme_minimal()
```

### RMSE difference by stream and year

```{r}
model_error_summary <- model_data_final %>%
  mutate(error_linear = abs(yday - pred_linear),
         error_quad   = abs(yday - pred_quad)) %>%
  group_by(stream, year) %>%
  summarize(
    n = n(),
    RMSE_linear = sqrt(mean((yday - pred_linear)^2)),
    RMSE_quad   = sqrt(mean((yday - pred_quad)^2)),
    .groups = "drop"
  ) %>%
  mutate(delta_RMSE = RMSE_linear - RMSE_quad)  # positive = quad is better

ggplot(model_error_summary, aes(x = year, y = delta_RMSE, fill = delta_RMSE > 0)) +
  geom_col(aes(alpha = n), position = "dodge") +
  facet_wrap(~stream) +
  scale_alpha(range = c(0.4, 1)) +
  scale_fill_manual(values = c("firebrick", "steelblue")) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(title = "ÎRMSE by Stream and Year", x = "Year", y = "RMSE: Linear â Quadratic", subtitle = "Alpha scaled to sample size") +
  theme_minimal() +
  theme(legend.position = "none")

```

-   facets show stream-level RMSE differences
-   patterns across years may highlight where curvature helps (e.g., early, warm, or dry years)

<!-- ### Final plots -->

```{r fig.height=12}
# # Panel A: Predicted Spawn Timing by Stream (Linear vs Quadratic)
# pred_linear <- ggeffects::ggpredict(final_model, terms = c("temp_90", "stream"))
# pred_quad   <- ggeffects::ggpredict(lm_poly, terms = c("temp_90", "stream"))
# 
# pred_linear$model <- "Linear"
# pred_quad$model   <- "Quadratic"
# 
# pred_both <- rbind(pred_linear, pred_quad)
# 
# pf1 <- ggplot() +
#   geom_point(data = model_data_final, aes(x = temp_90, y = yday), color = "grey", alpha = 0.3, size = 0.7) +
#   geom_line(data = pred_both, aes(x = x, y = predicted, color = group, linetype = model), size = 1.1) +
#   facet_wrap(~group) +
#   labs(title = "A) Predicted Spawn Timing by Stream",
#        x = "90-day Mean Temp", y = "Spawn Day of Year") +
#   theme_custom() +
#   theme(legend.position = "none")
# 
# 
# # Panel B: ÎRMSE by Stream Ã Year
# pf2 <- ggplot(model_error_summary, aes(x = year, y = delta_RMSE, fill = delta_RMSE > 0)) +
#   geom_col(position = "dodge") +
#   facet_wrap(~stream) +
#   geom_hline(yintercept = 0, linetype = "dashed") +
#   scale_fill_manual(values = c("firebrick", "steelblue")) +
#   labs(title = "B) Improvement from Quadratic Model (ÎRMSE)",
#        x = "Year", y = "RMSE: Linear â Quadratic") +
#   theme_custom() +
#   theme(legend.position = "none")
# 
# final_fig <- pf1 / pf2 + plot_layout(heights = c(1, 1))
# final_fig
```
