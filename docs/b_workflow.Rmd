---
title: "MFSR Chinook spawn timing analysis"
output:
  bookdown::html_document2:
    toc: true
    number_sections: true
    toc_depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: false
date: "`r format(Sys.time(), '%d %B, %Y')`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(tidyverse)
library(here)
library(patchwork)
library(lemon)
library(ggeffects)
library(lme4)
library(mgcv)
library(gratia)
library(MuMIn)
library(sjPlot)
library(broom)
library(performance)
library(DHARMa)

cols.streams <- c(
  "Bear Valley" = "#55FF00",
  "Beaver" = "#7A8EF5",
  "Big" = "#FFFF00",
  "Camus" = "#E64C00",
  "Elk" = "#D7D79E",
  "Loon" = "#7AF5CA",
  "Marsh" = "#DF73FF",
  "Sulphur" = "#FFAA00"
  )

cols.years <- c(
  "2002" = "#1B9E77", 
  "2003" = "#D95F02", 
  "2004" = "#7570B3", 
  "2005" = "#E7298A", 
  "2001" = "#66A61E"
  )

fixed_date <- as.Date("2000-12-31")
scale2 <- function(x, na.rm = FALSE) (x - mean(x, na.rm = na.rm)) / sd(x, na.rm)
summary_table <- function(model) {
  tidy(model)[, c("term", "estimate", "std.error", "p.value")]
}
```

```{r lgd-data}
# Lower granite dam counts -----------------------------------------------------
# lgd_chinook <-tibble(year = c(2002,2003,2004,2005),
#                      spring_chinook = c(75025,70609,70742,26028),
#                      spring_jacks = c(2089,8295,4482,1258),
#                      all_chinook = c(109535, 98763, 94469, 43958)) |> 
#   mutate(year = as.factor(year))
```

## Goal

Describe variation in spawn timing and how it relates to environmental covariates.

## Study area and species

This study was conducted in the Middle Fork of the Salmon River (MFSR) in central Idaho (\@ref(fig:map)). The MFSR is a tributary of the Salmon River and is part of the larger Columbia River Basin. The MFSR is home to several species of salmon, including Chinook salmon (*Oncorhynchus tshawytscha*).

```{r map, fig.width = 6, fig.height = 4, fig.cap = "Map of the Middle Fork Salmon River (MFSR) study area showing redd locations used in the analysis (2002-2005) and stream reaches."}
knitr::include_graphics(here("plots", "MFsalmonRedds_May2.jpg"))
```

**NOTE**: remove banner creek; add elevation gradient legend

## Data prep and inspection

### Spawn timing data

Spawn timing data for Chinook salmon were collected from 2001 to 2005 in the MFSR.

We removed data from 2001, and data from Knapp Creek and Cape Horn Creek, as these sites were not consistently sampled. Because redds were not observed daily, we inferred spawn dates as the initial date a completed redd was observed.

We joined each redd location to the NHD and assigned them a COMID, analogous to a stream reach. The COMID is used to link the spawn time data with covariate data associated with the stream reach on which it is located.

```{r spawn-data}
# data were compiled and clean in compile_mfsr_spawn.R and clean_mfsr_spawn.R
spawn_data <- read_csv(here("data", "russ_spawn", "mfsr_spawn_cleaned.csv"))

# remove bad data
spawn_data <- spawn_data |>
  filter(stream != "Knapp" & stream != "Cape Horn" & year != 2001) |> 
  mutate(
    year = as.factor(year), 
    stream = as.factor(stream), 
    COMID = as.factor(COMID), 
    DATE = mdy(DATE)
    ) |> 
  select(
    redd_id = UNIQUE_ID, COMID, spawn_date = DATE, stream, year, yday
  )
```

The data comprise `r nrow(spawn_data)` redd observation from `r length(unique(spawn_data$stream))` streams across `r length(unique(spawn_data$year))` years. The redds were observed between day `r min(spawn_data$yday)` and `r max(spawn_data$yday)`. Below we print the first 10 rows:

```{r spawn-data-tbl, caption = "First 10 observation in spawn dataset."}
spawn_data |>
  slice_head(n = 10) |> 
  kableExtra::kbl() |> 
  kableExtra::kable_styling("striped", full_width = FALSE)
```

#### Variation in spawn timing

```{r plot-spawn, fig.width=10, fig.height=8, fig.cap = "Histogram and density of spawn timing data (DOY) for all streams and years."}

# calculate mean yday for each year
yr_means <- spawn_data |> 
  group_by(year) |> 
  summarise(mean = mean(yday))

# historgram and density of spawn timing
p1 <- ggplot(spawn_data, aes(x = yday)) +
  geom_histogram(
    aes(y = after_stat(density)),
    bins = 30, fill = "gray70", color = "black"
  ) +
  geom_density(color = "black", size = 1.2) +
  geom_vline(aes(xintercept = mean(yday)),
    color = "black", linetype = "dashed", linewidth = 1.2
  ) +
  geom_vline(
    data = yr_means,
    aes(xintercept = mean, color = year), linewidth = 1.2
  ) +
  scale_color_manual(values = cols.years) +
  annotate(
    "text",
    x = 260, y = .06, hjust = 1, vjust = 1, size = 4.5,
    label = paste0
    (
      "mean = ", round(mean(spawn_data$yday), 2), "\n",
      "median = ", round(median(spawn_data$yday), 2), "\n",
      "min = ", round(min(spawn_data$yday), 2), "\n",
      "max = ", round(max(spawn_data$yday), 2), "\n",
      "var = ", round(var(spawn_data$yday), 2), "\n",
      "SD = ", round(sd(spawn_data$yday), 2)
    )
  ) +
  labs(
    title = "Histogram and Density of Spawn Dates",
    x = "Spawn Date (day of year)",
    y = "Density function\n of spawn dates",
    color = "Year"
  ) +
  theme_bw() +
  theme(
    legend.position = "inside",
    legend.position.inside = c(.1, .65),
    legend.title = element_blank(),
    legend.text = element_text(size = 8),
    legend.box.background = element_rect(colour = "black")
  )

# plot spawn date by stream
p2 <- spawn_data |> 
  ggplot(aes(x = stream, y = fixed_date + yday)) +
  geom_boxplot() +
  geom_jitter(aes(color = stream), size = 1.5, alpha = 0.1) +
  scale_color_manual(values = cols.streams) +
  scale_y_date(date_breaks = "2 weeks", date_labels = "%d %b") +
  coord_flip() +
  labs(
    title = "Spawn Date by Stream",
    x = "",
    y = "Spawn Date"
    ) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  guides(color = "none")

# Plot spawn date by year
p3 <- spawn_data |> 
  ggplot(aes(x = year, y = fixed_date + yday)) +
  geom_boxplot() +
  geom_jitter(aes(color = year), size = 1.5, alpha = 0.1) +
  scale_color_manual(values = cols.years) +
  scale_y_date(date_breaks = "2 weeks", date_labels = "%d %b") +
  coord_flip() +
  labs(
    title = "Spawn Date by Year",
    x = "",
    y = "Spawn Date"
  ) +
  theme_bw() +
  guides(color = "none")

# panel
p1 / ((p2 + p3) + 
  plot_layout(widths = c(1.5,1))) + 
  plot_annotation(tag_levels = "A")
```

Notes on the distribution of spawn timing data:

-   mean and median are equal, low SD
-   var \< mean (no overdispersion) data are right-skewed,
-   lumpy/multimodal, and not symmetric at least
-   Poisson family is response is count of spawning events per day,
-   Gaussian if model density as continuous

#### Spawn time variation by year and stream

```{r plot-spawn-yr-strm, fig.width=8, fig.height=8, fig.cap= "Spawn time variation by year and stream."}
spawn_data |>
  ggplot(aes(x = year, y = fixed_date + yday, color = year)) +
  lemon::facet_rep_wrap(~stream) + 
  geom_boxplot() + 
  geom_jitter(aes(color = year), size = 1.5, alpha = 0.1) +
  scale_color_manual(values = cols.years) +
  scale_y_date(date_breaks = "2 weeks", date_labels = "%d %b") +
  coord_flip() +
  labs(x = "", y = "Spawn Date") + 
  theme_bw() + 
  guides(color = "none")
```

#### Spawn time by COMID and stream

```{r plot-spawn-comid, fig.width=8, fig.height=8, fig.cap= "Spawn time by COMID and stream."}
spawn_data |> 
  ggplot(aes(x = COMID, y = fixed_date + yday, color = stream)) + 
  facet_wrap(~stream, scales = "free_y") +
  geom_boxplot() + 
  geom_jitter(aes(color = stream), size = 1.5, alpha = 0.1) +
  scale_color_manual(values = cols.streams) +
  scale_y_date(date_breaks = "2 weeks", date_labels = "%d %b") +
  coord_flip() +
  labs(x = "", y = "Spawn Date") + 
  theme_bw() + 
  theme(axis.text.x = element_text(angle = 90, size = 8)) + 
  guides(color = "none")
```

#### Spawn time distributions by stream

```{r plot-temp-dist-spawn, fig.width=8, fig.height = 8, fig.cap= "Spawning phenology of adult Chinook Salmon. In all panels, the black density function represented stream-level spawn timing, while the colored density functions represent the spawn timing of individual years. The dashed vertical purple lines represent the 5th and 95th percentiles of the basin-wide spawn timing."}
mfsr_by_site <- spawn_data |>
  group_by(stream, yday)

mfsr_all <- spawn_data |>
  summarise(
    median = median(yday),
    percentile_95 = fixed_date + quantile(yday, probs = 0.95),
    percentile_5 = fixed_date + quantile(yday, probs = 0.05)
  )

spawn_data |>
  mutate(across(year, as.character)) |>
  group_by(stream, year) |>
  ggplot(aes(x = fixed_date + yday)) +
  facet_rep_wrap(~stream, scales = "free_y", ncol = 2) +
  geom_density(
    aes(fill = year),
    alpha = 0.5) +
  geom_density(
    data = mfsr_by_site, alpha = 0, linetype = "dashed", color = "black") +
  geom_vline(
    xintercept = mfsr_all$median, 
    color = "blue", 
    linetype = "dashed") +
  geom_vline(
    xintercept = c(mfsr_all$percentile_95, mfsr_all$percentile_5), 
    color = "purple", 
    linetype = "dashed") +
  scale_fill_brewer(palette = "Dark2", name = "Year") +
  scale_x_date(date_breaks = "2 weeks", date_labels = "%d %b") +
  labs(x = "Date", 
       y = "Density function of spawn dates") +
  theme_bw()
```

#### Cumulative proportions of redds by stream

```{r plot-cum-props, , fig.width=8, fig.height = 8, fig.cap= "Cumulative proportion of completed of redds by stream."}
# Proportional cumulative redds ------------------------------------------------
# spawn_data %>%
#   group_by(stream, yday) %>%
#   tally() %>%
#   group_by(stream) %>%
#   arrange(yday) %>%
#   mutate(cumulative = cumsum(n)) %>%
#   ggplot(aes(x = yday, y = cumulative, color = stream)) +
#   geom_line() +
#   labs(title = "Cumulative Redd Counts", y = "Cumulative Redds") +
#   theme_bw()


# Proportional cumulative redds by stream --------------------------------------
# For each year and stream, calculate the prop. cumulative number of redds
props <- spawn_data |> 
  select(year, stream, yday) |>
  group_by(year, stream, yday) |>
  add_count() |> 
  distinct() |> 
  group_by(year, stream) |>
  arrange(year, stream, yday) |>
  mutate(cum_redds = cumsum(n)) |> 
  mutate(cum_redds_p = cum_redds / max(cum_redds))

# Plot pro. cumsums
props |> 
  ggplot(aes(x = fixed_date + yday, y = cum_redds_p, color = as.factor(year))) +
  lemon::facet_rep_wrap(~stream, ncol = 2, scales = "free_y") +
  geom_line(linewidth = 0.5) + 
  geom_point(size = 0.3) + 
  scale_y_continuous(limits = c(0,1), breaks = seq(0,1,0.5)) + 
  scale_color_manual(values = cols.years, name = "Year") +
  labs(
    x = "Day of Year",
    y = "Proportion of ccumulative redds",
    color = ""
  ) + 
  theme_bw()
```

#### COMID grouping structure {#comid-str}

```{r comid-counts}
# How many COMIDs have <5 observations?
n_sparse_COMIDS_5 <- spawn_data |> 
  count(COMID, name = "n_redds") |> 
  filter(n_redds < 5) |> 
  nrow()
n_sparse_COMIDS_2 <- spawn_data |> 
  count(COMID, name = "n_redds") |> 
  filter(n_redds <= 2) |> 
  nrow()

# what percent of comids have <= 1 obervation?
n_perc_1 <- spawn_data |>
  count(COMID, name = "n_redds") |>
  filter(n_redds <= 1) |>
  nrow() / length(unique(spawn_data$COMID)) * 100

n_perc_2 <- spawn_data |>
  count(COMID, name = "n_redds") |>
  filter(n_redds <= 2) |>
  nrow() / length(unique(spawn_data$COMID)) * 100

n_perc_5 <- spawn_data |>
  count(COMID, name = "n_redds") |>
  filter(n_redds <= 5) |>
  nrow() / length(unique(spawn_data$COMID)) * 100
```

```{r comid-str, caption = "Number of COMIDs per stream."}
# number of comids per stream
spawn_data |> 
  distinct(stream, COMID) |> 
  count(stream, name = "n_COMIDs") |> 
  arrange(desc(n_COMIDs)) |> 
  kableExtra::kbl() |> 
  kableExtra::kable_styling("striped", full_width = FALSE) 
```

```{r comid-str-plot, fig.width=6, fig.height=4, fig.cap = "Number of observations (redds) per COMID."}
# number of observations per COMID
spawn_data |> 
  count(COMID, name = "n_redds") |> 
  arrange(n_redds) |> 
  ggplot(aes(n_redds)) +
  geom_bar() + 
  scale_y_continuous(breaks = seq(0,10,1)) + 
  labs(title = "Number of obervations (redds) per COMID", 
       x = "Number of redds", 
       y = "Count") + 
  theme_bw()
```

##### Summary

Are the enough COMIDs per stream to consider stream/COMID nested random effects? Not really...

Are groups well sampled? (Do most COMIDs have \>1-2 redds?) No. `r n_sparse_COMIDS_5` COMIDs have \<5 redds (`r n_perc_5`%), `r n_sparse_COMIDS_2` have \<= 2. (`r n_perc_2`%). With \<5 obs/level, variance estimates become unstable -\> overfit and absorb noise (low AIC / high R2) -\> singular fits.

Are year or stream-level random effects justifiable? We want to compare streams and years in this dataset, not generalize beyond them, so we should use fixed effects. Further, stream are known, of interest, and were not randomly sampled. Including (1 \| stream) would be statistically redundant (stream intercepts would be double-modeled) and would lead to misleading AIC comparisons.

Random slopes?. The needs multiple obs per group across a range of slope variable (`temp_90`), enough replication to estimate variation in slopes, not just intercepts. Need \~8+ obs per group spread across the covariate. We could do this for stream or year. Prob not.

So, we should use a simple linear model with no random effects. This allows for interpretable results, no overfitting from random effects, and is a reasonable approach given the design.

If we did try (1 \| COMID), expect singularity, low variance estimates for COMID, and predictions will likely miss the groups means.

That said, as shown in below in the [Temp_90 Section](#sec-temp_90), we probably should be including COMID as a random effect. So we many have to simplify the model to ovoid over fitting.

### Covariates

To test for environmental factors driving variation in spawn timing, we quantified associations with metrics describing thermal and physical conditions in stream reaches. We selected covariates based on the following criteria: (1) they are known to influence spawn timing, (2) they are available for all streams, and (3) they are not highly correlated with each other. Our focal independent variable were:

-   stream temperature (°C)
-   stream discharge (cms)
-   elevation (m above sea level)
-   stream gradient (slope)

#### Stream temperature

We used modeled daily average stream temperature values predicted at the stream segment (COMID) scale (Siegel et al. 2023). These data were downloaded and filtered to 2001-2005 and for the MFSR.

```{r siegel-temp-data}
# temp data (see siegel_mfsr_temps.R)
df_temp <- readRDS(here::here("data/siegel_temperature/siegel_mfsr_comid.RDS"))

xref_comid_stream <- spawn_data |> 
  distinct(COMID, stream) 

# clean up
df_temp <- df_temp |>
  select(COMID, date = tim.date, temp = prd.stream_temp) |> 
  mutate(
    yday = yday(date), 
    year = as_factor(year(date)), 
    COMID = as.character(COMID)) |> 
  filter(COMID %in% spawn_data$COMID) |>
  filter(year %in% c("2001","2002","2003","2004","2005")) |>
  left_join(xref_comid_stream, by = "COMID") 
```

##### Summarized thermal regimes by stream

```{r plot-temp-regime, fig.width=8, fig.height=10, fig.cap = "Modeled thermal regimes (2001-2005) for MFSR tributaries. Black line = mean, Red ribbon = 40 - 60th percentiles, Grey ribbon = full range."}
# calculate 40 to 60th percentiles and full range for each COMID
df_temp_stream <- df_temp |> 
  group_by(stream, yday) |> 
  summarise(
    mean = mean(temp),
    temp_40 = quantile(temp, probs = 0.4),
    temp_60 = quantile(temp, probs = 0.6),
    temp_min = min(temp),
    temp_max = max(temp), 
    .groups = "drop"
  )

# plot ribbom of 40-60th percentiles and range over yday
df_temp_stream |> 
  ggplot(aes(x = fixed_date + yday)) +
  facet_rep_wrap(~stream, ncol = 2) +
  geom_ribbon(data = df_temp_stream, aes(ymin = temp_min, ymax = temp_max), fill = "grey") +
  geom_ribbon(data = df_temp_stream, aes(ymin = temp_40, ymax = temp_60), fill = "red") +
  geom_line(aes(y = mean), color = "black") + 
  scale_x_date(date_breaks = "1 month", date_labels = "%b") +
  scale_color_brewer(palette = "Accent") +
  labs(
    title = "Modeled thermal regimes (2001-2005) for MFSR tributaries",
    # subtitle = "Black line = mean, Red ribbon = 40 - 60th percentiles, Grey ribbon = full range",
    x = "", 
    y = "Daily water temperature (\u00b0C)",
    color = "Year"
  ) + 
  theme_bw() +
  theme(axis.title.y = ggtext::element_markdown())
```

##### Stream temperature metrics

We calculated metrics relative to a COMID a redd was constructed on and a redd completion date; before, after, and spanning the date. For example, temp_30_before is the average temperature for a COMID where a redd was constructed calculated over the previous 30 days. We did this for 30, 60, and 90 days. We also calculated a time invariant metric relative to a fixed date across all years that was chosen to represent an initial spawning window, e.g., August 1. The time invariant and after metrics were omitted from further consideration as preliminary data exploration showed weak if any relationship with spawn timing.

```{r temp-metrics}
# summarized temperature data (`out`), see (map_comid_temps.R)
load(here("data", "comid_temps.RData"))

temp_data <- out |>
  filter(period == "before" & duration %in% c(30, 60, 90)) |>
  pivot_wider(
    names_from = "duration", 
    values_from = avg_temp, 
    names_prefix = "temp_"
    ) |> 
  select(redd_id, COMID = comid, spawn_date, temp_30, temp_60, temp_90)
```

#### Discharge (streamflow)

Stream flow data were compiled from a single USGS Gage lower in the watershed (MF Salmon River at MF Lodge NR Yellow Pine ID - 13309220). Becuase flow data are not COMID- or stream-specific, it makes sense to think about and represent flow as an out-of-basin year effect that determines when adults make it back to the MFSR and initially onto the spawning grounds.

```{r usgs-flow-data}
# raw flow data (see flow_calculations.R)
df_flows <- read_csv(here::here("data", "mfsr_flow.csv"))

# get day of year and year
df_flows <- df_flows |> 
  select(date = Date, flow_cfs = Flow) |> 
  mutate(yday = yday(date), year = as_factor(year(date))) |> 
  mutate(flow_csm = flow_cfs * 0.028316846592) |> 
  filter(! year == "2001")
```

##### Inter-annual variability

```{r plot-flow, fig.width=8, fig.height=8, fig.cap = "Inter-annual variability in daily discharge (cfs) at MF Lodge USGS Gage 13309220."}
p.flow.1 <- df_flows |> 
  ggplot(aes(x = fixed_date + yday, y = flow_cfs  , color = year)) +
  geom_line() +
  scale_x_date(date_breaks = "1 month", date_labels = "%b") +
  scale_color_manual(values = cols.years, name = "Year") +
  labs(
    title = "Linear scale",
    x = "", 
    y = "Mean daily discharge (m<sup>3</sup> s<sup>-1</sup>)"
  ) + 
  theme_bw() + 
  theme(axis.title.y = ggtext::element_markdown()) + 
  theme(
    legend.position = "inside",
    legend.position.inside =  c(.8, .65), 
    legend.title = element_blank(),
    legend.text = element_text(size = 8),
    legend.box.background = element_rect(colour = "black")
    )

p.flow.2 <- df_flows |> 
  ggplot(aes(x = fixed_date + yday, y = flow_cfs  , color = year)) +
  geom_line() +
  scale_x_date(date_breaks = "1 month", date_labels = "%b") +
  scale_y_log10() +
  scale_color_manual(values = cols.years, name = "Year") +
  labs(
    title = "Log scale",
    x = "", 
    y = "",
    # y = "Mean daily discharge (m<sup>3</sup> s<sup>-1</sup>)"
  ) + 
  theme_bw() + 
  theme(axis.title.y = ggtext::element_markdown())  + 
  guides(color = "none")

# p.flow.1 + p.flow.2 + 
#   plot_layout(guides = "collect") + 
#   plot_annotation(title = "Measured discharge at MF Lodge, USGS Gage 13309220")

# calculate 40 to 60th percentiles and full range for each COMID
tmp <- df_flows |> 
  group_by(yday) |>
  summarise(
    mean = mean(flow_cfs),
    flow_40 = quantile(flow_cfs, probs = 0.4),
    flow_60 = quantile(flow_cfs, probs = 0.6),
    flow_10 = quantile(flow_cfs, probs = 0.1),
    flow_90 = quantile(flow_cfs, probs = 0.9), 
    .groups = "drop"
  )

# plot ribbom of 40-60th percentiles and range over yday
p.flow.3 <- tmp |> 
  ggplot(aes(x = fixed_date + yday)) +
  geom_ribbon(data = tmp, aes(ymin = flow_10, ymax = flow_90), fill = "grey") +
  geom_ribbon(data = tmp, aes(ymin = flow_40, ymax = flow_60), fill = "blue") +
  geom_line(aes(y = mean), color = "black") + 
  scale_color_brewer(palette = "Accent") +
  scale_x_date(date_breaks = "1 month", date_labels = "%b") +
  scale_y_log10() +
  labs(
    # title = "Measured discharge at MF Lodge, USGS Gage 13309220",
    subtitle = "Black line = mean, blue ribbon = 40 - 60th percentiles, Grey ribbon = full range",
    x = "", 
    y = "Log Daily discharge (ft<sup>3</sup> s<sup>-1</sup>)",
    color = "Year"
  ) + 
  theme_bw() +
  theme(axis.title.y = ggtext::element_markdown())


(p.flow.1 + p.flow.2 ) / p.flow.3 + 
  plot_annotation(title = "Measured discharge at MF Lodge, USGS Gage 13309220") + 
  plot_annotation(tag_levels = "A")
```

##### Flow metrics

We calculated flow metrics relative to a COMID a redd was constructed on and a redd completion date; before, after, and spanning the date.For example, temp_30_before is the average temperature for a COMID where a redd was constructed calculated over the previous 30 days. We did this for 30, 60, and 90 days. The spanning and after metrics were omitted from further consideration as preliminary data exploration showed weak if any relationship with spawn timing.

```{r flow-metrics}
# summarized flow data (see flow_calculations.R)
flow_data <- read_csv(here("data", "spawn_flows.csv"))
```

#### Elevation and stream gradient (slope)

Elevation and stream slope data were available at the COMID (stream reach) scale from the NHD.

```{r elev-slope-data}
# elevation and slope from NHD
df_elev_slope <- readRDS(here("data", "elevslope.rds")) |> 
  as_tibble() |> 
  mutate(mean_elevation = (MAXELEVSMO + MINELEVSMO) / 2 / 100) |> 
  select(COMID, slope = SLOPE, mean_elevation)
```

#### Combine datasets

```{r combine-data}
model_data <- spawn_data |>
  left_join(flow_data, by = "spawn_date") |> 
  left_join(temp_data |> select(-spawn_date,-COMID), by = "redd_id") |>
  left_join(df_elev_slope |> mutate(COMID = as.factor(COMID)), by = "COMID") |> 
  filter(slope < .2)

model_data|>
  slice_head(n = 5) |> 
  kableExtra::kbl() |> 
  kableExtra::kable_styling("striped", full_width = FALSE)
```

## Bivariate relationships with covariates

```{r plot-covars, fig.height=10}
plot_covariate <- function(data, covariate) {
  ggplot(data, aes_string(x = covariate, y = "yday")) +
    geom_point() +
    geom_smooth(method = "lm") +
    labs(x = covariate, y = "DOY") +
    theme_bw()
}
covariates <- c("temp_30", "flow_30", "temp_60", "flow_60", "temp_90", "flow_90", "slope", "mean_elevation")
plots <- map(covariates, ~ plot_covariate(model_data, .x))
gridExtra::grid.arrange(grobs = plots, ncol = 2)
```

-   `temp_30` = no relationship, drop
-   `temp_60` = good non-linear, drop for temp_90?
-   `temp_90` = better non-linear
-   `flow_30` and `flow_60` = similar decaying exponential
-   `flow_90` = inflections, interesting grouping really spreads out, year effect
-   `SLOPE` = no relationship, drop
-   `mean_elevation` = slightly negative linear?

## Check for co-linearity

```{r plot-colinearity, echo=TRUE, fig.width=10, fig.height=10}
model_data |> 
  select(temp_30, temp_60, temp_90, flow_30, flow_60, flow_90, mean_elevation) |> 
  GGally::ggpairs()
```

-   There is strong colinearity among temp variable. Retaining `temp_90` as it has the strongest relationship.
-   `flow_30` and `flow_60` are highly correlated with `flow_90.`
-   Keep `flow_90` as it has the strongest relationship.
-   elevation good to keep

Check VIFs with and without `flow_30` and `flow_60`:

```{r vifs, echo=TRUE}
car::vif(lm(yday ~ flow_30 + flow_60 + flow_90 + temp_90 + mean_elevation + stream + year, data = model_data))
car::vif(lm(yday ~ flow_90 + temp_90 + mean_elevation + stream + year, data = model_data))
```

-   more reason to drop `flow_30` and `flow_60`

## A closer look at covariates

### `Temp_90` {#sec-temp_90}

```{r plot-temp_90, fig.width=6, fig.height=6, fig.cap = "Spawn timing vs. 90-day mean temperature pre spawn."}
(ggplot(model_data, aes(x = temp_90, y = fixed_date + yday, color = year)) +
  geom_point() +
  geom_smooth(method = "lm") +
  scale_color_manual(values = cols.years) + 
  theme_bw() + 
  labs(y = "Date", x = "") + 
  theme(legend.position = "right")) /

(ggplot(model_data, aes(x = temp_90, y = fixed_date + yday, color = stream)) +
  geom_point() +
  geom_smooth(method = "lm") +
  scale_color_manual(values = cols.streams) + 
  labs(y = "Date", x = "90-day mean temp before spawning") + 
  theme_bw() + 
  theme(legend.position = "right")) +
  plot_annotation(title = "Spawn Timing vs. 90-day mean temperature pre spawn") + 
  plot_annotation(tag_levels = "A")
```

Observations:

-   clear positive relationship, certainly some non-linearity
-   stream- and year-level variation (interactions)

Check simple models for temp to examine functional structure and compare with AIC:

```{r temp_90-mods, echo=TRUE}
m1 <- lm(yday ~ temp_90, data = model_data)
m2 <- lm(yday ~ I(temp_90^2), data = model_data)
m3 <- lm(yday ~ temp_90 + year, data = model_data)
m4 <- lm(yday ~ temp_90 + year + stream, data = model_data)
m5 <- lm(yday ~ temp_90 * stream, data = model_data)
m6 <- lm(yday ~ temp_90 * stream + year, data = model_data)
m7 <- lm(yday ~ temp_90 * year + stream, data = model_data)
m8 <- lm(yday ~ temp_90 * stream + I(temp_90^2), data = model_data)
m9 <- lm(yday ~ temp_90 * stream + year + I(temp_90^2), data = model_data)
```

```{r aic-temp_90, caption = "Model selection for spawn timing vs. 90-day mean temperature."}
AIC(m1, m2, m3, m4, m5, m6, m7, m8, m9) |> 
  arrange(AIC) |> 
  mutate(delta = AIC - min(AIC)) |>
  kableExtra::kbl() |> 
  kableExtra::kable_styling("striped", full_width = FALSE)
```

Based on AIC, `m9` is best model: linear and quadratic temp effect, temp x stream interaction, additive year effect. The next best is `m6`, which is the same with no quadratic.

Let's plot the predictions from `m9` to see how well it fits the data.

```{r temp_90_preds, fig.height=10, fig.cap = "Predicted spawn timing by stream and year."}
new_data <- expand.grid(
  temp_90 = seq(min(model_data$temp_90), max(model_data$temp_90), length.out = 100), 
  stream = unique(model_data$stream), 
  year = unique(model_data$year)
)
new_data$I.temp_90.2 <- new_data$temp_90^2

pred_out <- predict(m9, newdata = new_data, se.fit = TRUE)
new_data$pred <- pred_out$fit
new_data$lower <- pred_out$fit - 1.96 * pred_out$se.fit
new_data$upper <- pred_out$fit + 1.96 * pred_out$se.fit

new_data |> 
  ggplot(aes(x = temp_90, y = fixed_date + pred)) + 
  geom_ribbon(aes(ymin = fixed_date + lower, ymax = fixed_date + upper), fill = "grey80", alpha = 0.4) + 
  geom_line(color = "steelblue") + 
  facet_rep_grid(stream ~ year) + 
  geom_point(data = model_data, aes(temp_90, fixed_date + yday)) +
  labs(
    title = "Predicted Spawn Timing by Stream and Year",
    subtitle = "Model: yday ~ temp_90 * stream + year + I(temp_90^2)",
    x = "90-day Mean Temperature", y = "Predicted Spawn Day"
  ) + 
  theme_bw()
```

Observations from the plot

-   Strong curvature captured overall
-   Panels show increasing concave-down trend

Notable spatial breaks in some streams

-   Big and Camas
    -   Both show discontinuities or grouping in temp ranges with clear vertical offsets
    -   Possibly distinct COMIDs (upper vs. lower Big or Camas)
    -   Or abrupt temperature transitions across years or geomorphic controls (elevation?)
-   Loon and Marsh
    -   Patterns are tighter but still show micro-clustering → likely subtle COMID-level shifts.

Interpretation

-   Quadratic model captures macro-scale thermal responses well
-   But within-stream variation suggests that local (COMID-scale) differences are meaningful.
-   Stream-wide models may oversmooth important spatial heterogeneity.
-   Finer-scale modeling (e.g., random intercepts for COMID) could account for these offsets.

Visual inspection of stream- and year-specific fits revealed curvature in temperature–spawn timing relationships, with apparent within-stream variation in baseline timing across COMIDs. This suggested spatial heterogeneity not explained by stream-level fixed effects alone.

To account for this, we evaluated the addition of random intercepts for COMID with both top models (`m6` and `m9`).

```{r temp_90-mods-re, echo=TRUE}
m6_re <- lmer(yday ~ temp_90 * stream + year + (1|COMID), data = model_data)
m9_re <- lmer(yday ~ temp_90 * stream + year + I(temp_90^2) + (1|COMID), data = model_data)
```

```{r aic-temp_90-re, caption = "Model selection for spawn timing vs. 90-day mean temperature with random intercepts."}
AIC(m6, m9, m6_re, m9_re) |> 
  arrange(AIC) |> 
  mutate(delta = AIC - min(AIC)) |>
  kableExtra::kbl() |> 
  kableExtra::kable_styling("striped", full_width = FALSE)
```

1.  Effect of COMID Random Intercepts

-   Comparing `m6` vs `m6_re` (same fixed effects, RE added): ΔAIC = 2796.1
-   Massive improvement → shows strong unmodeled structure at the COMID level
-   Including (1 \| COMID) is important

2.  Effect of Quadratic Term

-   Comparing `m6_re` vs `m9_re`: ΔAIC = 38.7
-   evidence that the quadratic term explains real signal beyond COMID-level differences
-   The curvature isn't just compensating for omitted structure — it's meaningful even when that structure is accounted for

3.  Quadratic w/o RE vs Linear w/ RE

-   `m9` (quadratic only) still has a much worse AIC than `m6_re` (linear w/ RE): 15602 vs 13050 → ΔAIC ≈ 2552
-   This shows that random effects contribute far more than nonlinearity alone
-   But combining them (in `m9_re`) gives best performance

Takeaways

-   Random intercepts account for baseline spawn timing differences between reaches
-   the quadratic temperature effect describes a real, nonlinear thermal response
-   The combined model (`m9_re`) is supported: reflects spatial variation and nonlinear phenological drivers

Plot predictions with random intercepts:

```{r temp_90_preds-re, fig.height=10, fig.cap = "Predicted spawn timing by stream and year with random intercepts."}
# Create one row per COMID with its associated stream
comid_stream_lookup <- model_data %>%
  select(COMID, stream) %>%
  distinct()

# Expand across temp_90 sequence
temp_seq <- seq(min(model_data$temp_90), max(model_data$temp_90), length.out = 100)

newdata <- expand.grid(
  temp_90 = temp_seq,
  COMID = unique(model_data$COMID)
  )  |> 
  left_join(comid_stream_lookup, by = "COMID")  |> 
  mutate(year = "2004")

# m6_re -----
# newdata$pred <- predict(m6_re, newdata = newdata, re.form = NULL)
# 
# ggplot(newdata, aes(x = temp_90, y = fixed_date + pred, group = COMID, color = COMID)) +
#   facet_wrap(~stream) +
#   geom_line(alpha = 0.6) +
#   geom_point(data = model_data, aes(temp_90, fixed_date + yday), alpha = 0.2) +
#   labs(title = "Predicted Spawn Timing by COMID",
#        subtitle = "Model: yday ~ temp_90 * stream + year + (1|COMID)",
#        x = "90-day Mean Temperature", y = "Predicted Spawn Day") +
#   theme_minimal() +
#   theme(legend.position = "none")

## m9_re ----
newdata_comid <- expand.grid(
  temp_90 = temp_seq,
  COMID = unique(model_data$COMID)
) %>%
  left_join(comid_stream_lookup, by = "COMID") %>%
  mutate(year = "2004",  # or any fixed value
         I.temp_90.2. = temp_90^2)

newdata_comid$pred <- predict(m9_re, newdata = newdata_comid, re.form = NULL)

p.m9 <- newdata_comid |> 
  ggplot(aes(x = temp_90, y = fixed_date + pred, group = COMID, color = COMID)) +
  facet_wrap(~stream, ncol = 4) +
  geom_line(alpha = 0.6) +
  geom_point(data = model_data, aes(temp_90, fixed_date + yday), alpha = 0.2) +
  labs(title = "Predicted Spawn Timing by COMID",
       subtitle = "Model: yday ~ temp_90 * stream + year + I(temp_90^2) + (1|COMID)",
       x = "90-day Mean Temperature before spawn", y = "Predicted Spawn Day") +
  theme_bw() +
  theme(legend.position = "none")


# Check random intercepts
ranef_comid <- ranef(m9_re)$COMID
ranef_comid$COMID <- rownames(ranef_comid)

p.m9.re <- ranef_comid |> 
  ggplot(aes(x = reorder(COMID, `(Intercept)`), y = `(Intercept)`)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "grey40") +
  coord_flip() +
  labs(title = "Random Intercepts by COMID",
       y = "Intercept Deviation", x = "COMID") +
  theme_bw()

p.m9 / p.m9.re + 
  plot_annotation(tag_levels = "A") + 
  plot_layout(ncol = 1, heights = c(2, 1))
```

What this shows:

-   Vertical offsets in curves within each stream = COMID-specific random intercepts
-   The inclusion of (1 \| COMID) is doing its job — capturing consistent differences in spawn timing offset between reaches

Streams with wide COMID spread:

-   Big, Camas, and Bear Valley stand out

Streams with tight COMID clustering:

-   Sulphur, Marsh, Loon show tighter fits

The simplified model with COMID random intercepts is capturing reach-level variation without overwhelming the model. This is a strong candidate structure to carry forward or use as a baseline for comparing against more complex interaction models.

**Thoughts from Dan:** Temporal compression in lower reaches?

Dan's field observation: fish in warmer, lower reaches spawn later and over a shorter window.

Upstream vs. downstream dynamics in Big, Camas, Loon, etc. likely manifest in:

-   Vertical intercept shifts (already captured by (1 \| COMID))
-   But also differences in slope (i.e., how they respond to temperature)
-   the latter may suggest a true linear effect on much smaller spatial scales

**Statistical implication:**

Should we add COMID slopes?

The next logical step is to consider random slopes. This lets each COMID have its own slope for `temp_90`, capturing different rates of response to temperature.

But… we have a large overfitting risk! Random slopes are data-hungry. So with sparse COMID-level samples, this model will:

-   Almost certainly be singular
-   Overfit slope noise as signal
-   Widen uncertainty bands a lot

So — stick with random intercepts, and revisit slopes later only if:

-   We restrict to high-sample COMIDs
-   Or pool into zones (e.g., upper/lower) for slope comparisons

**Conclusion**

I think we will proceed and compare the full interaction model with and without the quadratic term. We'll Stick with (1 \| COMID) for now — it gets the key structure without overfitting. And flag a future option to explore grouped random slopes, or COMID × temp_90 interaction if biologically and statistically justified.

### `Flow_90`

```{r plot-flow_90, fig.width=6, fig.height=6, fig.cap = "Spawn timing vs. 90-day mean discharge pre spawn at MF Lodge."}
(ggplot(model_data, aes(x = flow_90, y = fixed_date + yday, color = year)) +
  geom_point() +
  geom_smooth(method = "lm") +
  scale_color_manual(values = cols.years) + 
  labs(x = "", y = "Date") + 
  theme_bw() + 
  theme(legend.position = "right")) /

(ggplot(model_data, aes(x = flow_90, y = fixed_date + yday, color = stream)) +
  geom_point() +
  geom_smooth(method = "lm") +
  scale_color_manual(values = cols.streams) + 
  labs(x = "90-day mean flow (CFS) pre spawn", y = "Date") + 
  theme_bw() + 
  theme(legend.position = "right")) + 
  plot_annotation(title = "Spawn Timing vs. 90-day mean flow pre spawn") + 
  plot_annotation(tag_levels = "A")
```

-   clear negative relationship, higher 90-day mean flows are associated with earlier spawn timing
-   relationship differs by year: 2003 linear but flattening or non-linear at higher flows
-   suggest different slopes or curves across years (year specific responses, but just intercepts)
-   stream-level variation as well, different intercepts and slopes
-   this is really a year effect with variation by stream and comid (local)

Check simple models for flow to examine functional structure and comapare with AIC:

```{r flow_90_mods, echo=TRUE}
m1 <- lm(yday ~ flow_90, data = model_data)
m2 <- lm(yday ~ I(flow_90^2), data = model_data)
m3 <- lm(yday ~ flow_90 + year, data = model_data)
m4 <- lm(yday ~ flow_90 + year + stream, data = model_data)
m5 <- lm(yday ~ flow_90 * stream, data = model_data)
m6 <- lm(yday ~ flow_90 * stream + year, data = model_data)
m7 <- lm(yday ~ flow_90 * year + stream, data = model_data)
m8 <- lm(yday ~ flow_90 * stream + I(flow_90^2), data = model_data)
m9 <- lm(yday ~ flow_90 * stream + year + I(flow_90^2), data = model_data)
```

```{r aic-flow_90, caption = "Model selection for spawn timing vs. 90-day mean flow."}
AIC(m1, m2, m3, m4, m5, m6, m7, m8, m9) |> 
  arrange(AIC) |> 
  mutate(delta = AIC - min(AIC)) |>
  kableExtra::kbl() |> 
  kableExtra::kable_styling("striped", full_width = FALSE)
```

-   best is `m7`: yday \~ flow_90 \* year + stream
-   flow x year interaction, additive stream effect

Let's plot the predictions from `m7` to see how well it fits the data.

```{r flow_90_preds_year, fig.height=4, fig.cap = "Predicted spawn timing by year."}
# new_data <- expand.grid(
#   flow_90 = seq(min(model_data$flow_90), max(model_data$flow_90), length.out = 100), 
#   stream = unique(model_data$stream)[1], 
#   year = unique(model_data$year)
# )
# pred_out <- predict(m7, newdata = new_data, se.fit = TRUE)
# new_data$pred <- pred_out$fit
# new_data$lower <- pred_out$fit - 1.96 * pred_out$se.fit
# new_data$upper <- pred_out$fit + 1.96 * pred_out$se.fit
# 
# new_data |> 
#   ggplot(aes(x = flow_90, y = fixed_date + pred)) + 
#   facet_rep_grid(~year) + 
#   geom_ribbon(aes(ymin = fixed_date + lower, ymax = fixed_date + upper), fill = "grey80", alpha = 0.4) + 
#   geom_line(color = "steelblue") + 
#   geom_point(data = model_data, aes(flow_90, fixed_date + yday)) +
#   labs(
#     title = "Predicted Spawn Timing by Year",
#     subtitle = "Model: yday ~ flow_90 * year + stream",
#     x = "90-day Mean Flow", y = "Predicted Spawn Day"
#   ) + 
#   theme_bw()
```

```{r flow_90_preds_all, fig.height=10, fig.cap = "Predicted spawn timing by stream and year."}
new_data <- expand.grid(
  flow_90 = seq(min(model_data$flow_90), max(model_data$flow_90), length.out = 100), 
  stream = unique(model_data$stream), 
  year = unique(model_data$year)
)
pred_out <- predict(m7, newdata = new_data, se.fit = TRUE)
new_data$pred <- pred_out$fit
new_data$lower <- pred_out$fit - 1.96 * pred_out$se.fit
new_data$upper <- pred_out$fit + 1.96 * pred_out$se.fit

new_data |> 
  ggplot(aes(x = flow_90, y = fixed_date + pred)) + 
  geom_ribbon(aes(ymin = fixed_date + lower, ymax = fixed_date + upper), fill = "grey80", alpha = 0.4) + 
  geom_line(color = "steelblue") + 
  facet_rep_grid(stream ~ year) + 
  geom_point(data = model_data, aes(flow_90, fixed_date + yday)) +
  labs(
    title = "Predicted Spawn Timing by Year and Stream",
    subtitle = "Model: yday ~ flow_90 * year + stream",
    x = "90-day Mean Flow", y = "Predicted Spawn Day"
  ) + 
  theme_bw()
```

1.  Strong, consistent negative relationship across panels

-   This is a strong, consistent pattern across all years and streams.
-   Suggests that higher pre-spawn flow leads to earlier spawning
-   ecologically plausible if higher flows coincide with snowmelt recession or cooler temps.

2.  Variation in slope

-   Slopes diverge across years, meaning the `flow_90` × year interaction may be statistically retained and meaningfully variable.
-   This suggests a non-stationary flow effect over the four years.

3.  Flow is clearly confounded with year

-   Flow values in each year are clearly distinct
-   `flow_90` behaves like a proxy for year, and its explanatory power may be redundant with year.
-   `flow_90` is still a basin-wide measure, not stream-specific
-   Even if the relationship looks strong here, it may artificially inflate R² because it imposes a covariate that’s similar across streams for a given redd's spawn date.
-   Could explain strong apparent fits without truly representing local flow conditions.

**Ecological Interpretation**

Spawn timing is earlier in years or settings with higher pre-spawn flow" — this makes sense, especially if:

-   Higher flows coincide with spring snowmelt → fish advance spawning
-   Lower flows delay environmental cues

But this doesn't necessarily mean site-specific flow is a driver. Just that `flow_90` tracks broader seasonal variation (i.e., interannual hydrology), already captured by year.

Flow could be valid in a year-based model, or as a year-level summary, but not site-level unless spatially resolved.

#### To include or not to include flow_90?

Including `flow_90` could introduce spurious precision and possibly overfitting. Why `flow_90` might be problematic:

1.  Not spatially resolved

-   We are modeling spawn timing at the redd level (COMID/stream)
-   But `flow_90` is calculated from a single downstream gauge, and applied to all redds
-   This assumes flow conditions are identical across all sites, which is rarely true in a branching stream network
-   Including it gives the illusion of spatially resolved variation that isn’t there

2.  Likely correlated with year

-   Since `flow_90` varies mostly across years, (albeit slightly with streams), it is strongly confounded with year
-   Any flow-related signal is probably already captured by your year fixed effect
-   Including both `flow_90` and year risks collinearity, and may produce misleading inferences

3.  Spawn-time aligned flow ≠ experienced flow

-   While `flow_90` is aligned to each redd’s spawn date, it still reflects a lower-basin gauge, not the actual hydrologic conditions experienced at the redd site
-   So it might be precisely wrong — aligned in time but irrelevant in space

**Bottom Line**:

Unless we have site-specific or spatially disaggregated flow data, flow_90 is probably not a valid covariate for redd-level models.

Including it may:

-   Overfit due to noise or pseudo-replication
-   Complicate interpretation (e.g., why one stream "responds" to flows measured elsewhere?)
-   Mask true year or site effects

**Recommendation**:

Drop `flow_90` from model (or at most, keep it as a year-level covariate if we summarize it to a single annual value for all observations)

**Text for ms**:

Although we initially considered including 90-day mean streamflow (`flow_90`) as a predictor of spawn timing, this variable was ultimately excluded due to concerns about ecological validity and model overfitting. Streamflow data were derived from a single downstream USGS gauge and did not capture spatial variation across the study streams or reaches. Moreover, because `flow_90` was closely aligned with year, it introduced strong collinearity with the year effect and risked attributing site-level variation to flow patterns not actually experienced by individual redds. As such, we excluded `flow_90` to avoid misleading inference.

## Final dataset and scale covariates

The final dataset includes:

-   response: spawn time (`yday`), continuous
-   grouping variables: `comid`, `stream`, `year`
-   covariates: `temp_90`, `elevation`

We scaled the continuous covariates to have a mean of 0 and standard deviation of 1. This is important for mixed models, as it helps with convergence and interpretation.

```{r final-dataset, caption = "Final dataset for modeling, first 5 rows."}
# selct variable sand scale
# model_data_final <- model_data |>
#   select(yday, COMID, stream, year, temp_90, mean_elevation, slope) |>
#   mutate(across(c("temp_90", "mean_elevation", "slope"), scale2))

model_data_final <- model_data |>
  select(yday, COMID, stream, year, temp_90_raw = temp_90, mean_elevation_raw = mean_elevation, slope_raw = slope) |>
  mutate(temp_90 = scale2(temp_90_raw), 
         mean_elevation = scale2(mean_elevation_raw), 
         slope = scale2(slope_raw)
         )

model_data_final |> 
  slice_head(n = 5) |> 
  kableExtra::kbl() |> 
  kableExtra::kable_styling("striped", full_width = FALSE)
```

## Model specification

### Fixed and random effects

We should only include a grouping variable as both fixef and ranef when you want to model differenct aspects of the effect. E.g., stream as fixed to compared average effects by stream, but as ranefs to account for non-independence of obs within each stream but not to compare average effects. We include as both when you want population-level estimates AND when you expect stream-level random variation around those means. Do not include both when intercepts are redundant (\~ stream + (1\| stream)), or too few levels for the random effect to be estimated (e.g., \<5 levels).

| Variable | Fixed? | Random? | Why |
|----------|------------------|------------------|------------------|
| `COMID` | No | Yes (but must check data availability among levels; likely sparse) | Not estimating individual COMID effects, just accounting for correlation. |
| `Stream` | Yes (comparing streams) | Maybe (account for among-stream variability) | May want to estimate differences and account for grouping. |
| `Year` | Yes (comparing years) | Maybe (account for inter-annual variability) | Use one or the other depending on goal. |

Given sparse data at the `COMID` scale as shown in [COMID Grouping Sturcture Section](#comid-str), we will include `COMID` as a random effect. This allows us to account for the correlation among observations within each COMID, but not estimate the average effect of COMID on spawn timing.

`Stream` is included as a fixed effects. This allows us to estimate the average effect of stream on spawn timing (but not also accounting for the correlation among observations within each stream).

In this case, it makes sense to include `year` as fixed because:

-   only has 4 levels - so a ranef would estimate variance poorly and shrink aggressively
-   year captures unmeasured inter annual variability (snow pack, flow, temp anomalies all wrapped in)
-   we want to compare among years given we only have 4 years of data, hard to extrapolate

### Simple linear models

First, we fit simple linear models to the data using all combinations of the fixed effects (n=31). This is a brute-force approach to model selection, but it allows us to see how each fixed effect contributes to the model fit.

```{r simple-lm, echo=TRUE}
# All combinations of 1–5 fixed effects: temp_90, stream, year, mean_elevation, SLOPE
# 31 total
m1 <- lm(yday ~ temp_90, data = model_data_final)
m2 <- lm(yday ~ stream, data = model_data_final)
m3 <- lm(yday ~ year, data = model_data_final)
m4 <- lm(yday ~ mean_elevation, data = model_data_final)
m5 <- lm(yday ~ slope, data = model_data_final)

m6  <- lm(yday ~ temp_90 + stream, data = model_data_final)
m7  <- lm(yday ~ temp_90 + year, data = model_data_final)
m8  <- lm(yday ~ temp_90 + mean_elevation, data = model_data_final)
m9  <- lm(yday ~ temp_90 + slope, data = model_data_final)
m10 <- lm(yday ~ stream + year, data = model_data_final)
m11 <- lm(yday ~ stream + mean_elevation, data = model_data_final)
m12 <- lm(yday ~ stream + slope, data = model_data_final)
m13 <- lm(yday ~ year + mean_elevation, data = model_data_final)
m14 <- lm(yday ~ year + slope, data = model_data_final)
m15 <- lm(yday ~ mean_elevation + slope, data = model_data_final)

m16 <- lm(yday ~ temp_90 + stream + year, data = model_data_final)
m17 <- lm(yday ~ temp_90 + stream + mean_elevation, data = model_data_final)
m18 <- lm(yday ~ temp_90 + stream + slope, data = model_data_final)
m19 <- lm(yday ~ temp_90 + year + mean_elevation, data = model_data_final)
m20 <- lm(yday ~ temp_90 + year + slope, data = model_data_final)
m21 <- lm(yday ~ temp_90 + mean_elevation + slope, data = model_data_final)
m22 <- lm(yday ~ stream + year + mean_elevation, data = model_data_final)
m23 <- lm(yday ~ stream + year + slope, data = model_data_final)
m24 <- lm(yday ~ stream + mean_elevation + slope, data = model_data_final)
m25 <- lm(yday ~ year + mean_elevation + slope, data = model_data_final)

m26 <- lm(yday ~ temp_90 + stream + year + mean_elevation, data = model_data_final)
m27 <- lm(yday ~ temp_90 + stream + year + slope, data = model_data_final)
m28 <- lm(yday ~ temp_90 + stream + mean_elevation + slope, data = model_data_final)
m29 <- lm(yday ~ temp_90 + year + mean_elevation + slope, data = model_data_final)
m30 <- lm(yday ~ stream + year + mean_elevation + slope, data = model_data_final)

m31 <- lm(yday ~ temp_90 + stream + year + mean_elevation + slope, data = model_data_final)
```

```{r simple-lm-better}
# Do the above better -----------------
# # All combinations of 1–5 fixed effects: temp_90, stream, year, mean_elevation, slope
# fixed_vars <- c("temp_90", "stream", "year", "mean_elevation", "slope")
# 
# # Generate all additive model formulas
# fixed_formulas <- unlist(lapply(1:length(fixed_vars), function(k) {
#   combn(fixed_vars, k, simplify = FALSE)
# }), recursive = FALSE)
# 
# models <- list()
# 
# for (i in seq_along(fixed_formulas)) {
#   fmla_str <- paste("yday ~", paste(fixed_formulas[[i]], collapse = " + "))
#   models[[paste0("m", i)]] <- lm(as.formula(fmla_str), data = model_data)
# }
# 
# # Compare with AIC
# model_aic_table <- AICc(models[[1]])
# for (i in 2:length(models)) {
#   model_aic_table <- rbind(model_aic_table, AICc(models[[i]]))
# }
# 
# # Name rows for clarity
# rownames(model_aic_table) <- names(models)
# model_aic_table |> 
#   rownames_to_column() |> 
#   rename(model = rowname, AIC = V1) |> 
#   mutate(delta = AIC - min(AIC)) |> 
#   arrange(delta) |> 
#   as_tibble()
```

```{r aic-simple-lm, caption = "Model selection for addtive LMs. Top 10 of 31 shown."}
aic_tab <- AIC(m1,m2,m3,m4,m5,m6,m7,m8,m9,m10,m11,m12,m13,m14,m15,m16,m17,
    m18,m19,m20,m21,m22,m23,m24,m25,m26,m27,m28,m29,m30,m31) |> 
  arrange(AIC) |> 
  rownames_to_column(var = "Model") |>
  mutate(delta = AIC - min(AIC)) |> 
  as_tibble()

aic_tab |> 
  slice_head(n = 5) |>
  kableExtra::kbl() |>
  kableExtra::kable_styling("striped", full_width = FALSE)
```

**Interpretation:**

✅ Model `m31` is best fit based on AIC

-   Contains all five covariates
-   Suggests that each adds unique, non-redundant signal
-   Likely a solid benchmark
-   But might be at risk of overfitting or including covariates of weak effect

🔻 Model `m26`

-   Drops `slope` → minimal ΔAIC (Δ = 84)
-   Suggests slope may not be that influential when year and elevation are included

🔻 Model `m27` - Drops `mean_elevation` → ΔAIC = 341

-   Implies elevation likely provides more explanatory power than slope in this model context

🔻 Model `m16` - Drops both `mean_elevation` and `slope`

-   Still relatively good (Δ = 395)
-   `temp_90 + stream + year` explains the bulk of variation

🔻 Model `m28` - general model as suggest by Dan -

-   Omits `year`, includes everything else → ΔAIC = 1100
-   Big drop confirms that `year` is critically important, likely absorbing interannual hydrology, climate variation, or escapement.

**Takeaways:**

-   `year` and `stream` are foundational — they’re in all top models.
-   `temp_90` is always present — unsurprisingly.
-   `mean_elevation` is more helpful than `SLOPE`, but may interact or confound in full models
-   `SLOPE` adds little alone but may act synergistically in certain combinations.

**Recommendation:**

-   Retain `year`, `stream`, and `temp_90` in all subsequenct models
-   Explore parameter estimates from top models to see if elevation and slope are meaningful

Look at the model estimates for top 5 models:

```{r}
tab_model(
  m31, m26, m27, m16, m28, 
  dv.labels = c(
    "Full model", "No slope", "No elevation", "No elevation or slope", "No year"),
  CSS = list(
    css.table = "+font-size: 0.6em; +font-family: Arial;",
    css.footnote = "font-size: 0.8em;"
    )
  )
```

**Consistent Predictors**

-   `temp_90`, `stream` and `year` are consistently significant across all top models.
-   Their estimates are stable and interpretable. These should be locked in as core covariates.

**Elevation vs. Slope**

-   `mean_elevation` has a small effect, yet significant
-   `SLOPE` is more variable:
-   removing `SLOPE` from the top model (`m26`) causes only a moderate AIC jump (ΔAIC \~84)
-   `mean_elevation` is probably doing more work than `SLOPE`, but neither may be critical once `stream` and `year` are accounted for.

**Watch for redundancy**

-   In `m31`, both `stream` and `mean_elevation` are included.
-   If `mean_elevation` is mostly captured by stream identity or COMID, it may be redundant.

**Recommendations**

-   Retain: `temp_90`, `stream`, `year`
-   Keep `mean_elevation` if effect size is consistent and interpretable
-   Drop `SLOPE` unless it provides a strong ecological rationale

**Next Step:**

-   Try a version of the best model without `mean_elevation` and `SLOPE`, or just `mean_elevation`, to test sensitivity
-   Proceed to adding the quadratic term (`I(temp_90^2)`)
-   Then test `COMID` as a random intercept - test interactions

**Why should we compare targeted models first?**

-   We've already identified that `temp_90`, `stream`, and `year` are critical
-   `mean_elevation` and `SLOPE` are questionable in explanatory value
-   Including interactions too soon could:
    -   Mask whether those weaker covariates matter
    -   Inflate model complexity before locking in the core structure

**Therefore, we will compare:**

-   `temp_90` + `stream` + `year` (baseline)
-   Add `mean_elevation` and/or `SLOPE`
-   Then add `I(temp_90^2)`
-   Then add `(1 | COMID)`

This gives us a clean sense of model structure before going into interactions.

### Targeted model comparison

```{r targ-models, echo=TRUE}
# Targeted Model Comparisons (pre-interaction)
# Clean models to confirm key structure and quadratic temp effect
mod_base <- lm(yday ~ temp_90 + stream + year, data = model_data_final)
mod_elev <- lm(yday ~ temp_90 + stream + year + mean_elevation, data = model_data_final)
mod_quad <- lm(yday ~ temp_90 + I(temp_90^2) + stream + year, data = model_data_final)
mod_quad_elev <- lm(yday ~ temp_90 + I(temp_90^2) + stream + year + mean_elevation, data = model_data_final)
mod_quad_re <- lmer(yday ~ temp_90 + I(temp_90^2) + stream + year + (1 | COMID),
                    data = model_data_final, REML = FALSE)
mod_quad_re_elev <- lmer(yday ~ temp_90 + I(temp_90^2) + stream + year + mean_elevation + (1 | COMID),
                    data = model_data_final, REML = FALSE)
```

```{r aic-targeted-models, caption = "Model selection for targeted models."}
AIC(mod_base, mod_elev, mod_quad, mod_quad_elev, mod_quad_re, mod_quad_re_elev) |> 
  mutate(delta = AIC - min(AIC)) |>
  arrange(delta) |> 
  kableExtra::kbl() |>
  kableExtra::kable_styling("striped", full_width = FALSE)
```

```{r targ-mod-params, caption = "Parameter estimates for target models."}
tab_model(
  mod_base, mod_elev, mod_quad, mod_quad_elev, mod_quad_re, mod_quad_re_elev,
  dv.labels = c(
    "mod_base", "mod_elev", "mod_quad", "mod_quad_elev", "mod_quad_re", "mod_quad_re_elev"),
  CSS = list(
    css.table = "+font-size: 0.6em; +font-family: Arial;",
    css.footnote = "font-size: 0.8em;"
    )
  )
```

🧠 Interpretation:

-   Adding COMID random intercepts (`mod_quad_re`) yields a dramatic improvement (ΔAIC \> 2,000) over any fixed-only model.
-   Adding elevation to that model (`mod_quad_re_elev`) gives a modest ΔAIC = 120.
-   However, this could reflect minor spatial confounding that’s also captured by `stream`or `(1|COMID)`.
-   Suggests `mean_elevation` is absorbed by COMID-level differences.
-   So: `COMID` matters, elevation maybe helps, but not by much.

🔎 Fixed Effects Summary (Coefficients Table)

Here are key takeaways across models (focus on `mod_quad_re` and `mod_quad_re_elev`):

✅ Significant Predictors:

-   `temp_90`: strongly positive (e.g., 18.6 days per °C in `mod_quad_re`)
-   `temp_90^2`: negative (\~–0.34 to –0.67), supporting a nonlinear relationship: spawn timing rises with temp but levels off or declines at higher values
-   `stream` effects: large and significant, especially in Camas, Big, Loon
-   `year` effects: significant, showing interannual shifts (\~2–5 days)

🟡 `mean_elevation`:

-   Coefficient is positive but tiny (e.g., 0.06 ± 0.005) in `mod_quad_re_elev`
-   p \< 0.001, so statistically significant — but effect size is negligible
-   Likely absorbed in `COMID` and `stream` effects

⚠️ `temp_90^2` (quadratic):

-   Coefficients are consistent across models and significant
-   Negative sign supports a concave-down effect (i.e., delayed spawning only up to a point)

| **Element** | **Role in Model** | **Notes** |
|---------------|-----------------------|-----------------------|
| `temp_90` | Strongest predictor | Linear increase in spawn timing with warmer temps |
| `temp_90^2` | Justifies nonlinear (concave) curve | Suggests thermal limits or saturation effects |
| `stream` | Critical for spatial variation | Captures strong reach-scale effects on phenology |
| `year` | Necessary for interannual climate/hydrology | Model fit suffers without it |
| `(1|COMID)` | Essential for reach-scale heterogeneity | Explains residual variation across \~100 segments |
| `elevation` | Weak (despite p \< 0.001) | Tiny effect, possibly collinear with `stream` or `COMID` |

✅ Recommendations

**Final Model Candidate:**

-   `mod_quad_re` — strong fit, interpretable, no redundancy
-   Keep: `temp_90`, `I(temp_90^2)`, `stream`, `year`, and `(1 | COMID)`
-   Drop: `mean_elevation` (already accounted for in `(1|COMID)`

**Optional:**

-   We could retain `mod_quad_re_elev`, but elevation’s gain (ΔAIC = 120) may not justify added complexity
-   If out goal is generalizability or to avoid collinearity, drop elevation

### Interactions

We will now test interactions and compare them to `mod_quad_re`.

```{r int-mods, echo=TRUE}
mod_interact1 <- lmer(yday ~ temp_90 * stream + year + I(temp_90^2) + (1 | COMID), data = model_data, REML = FALSE)
mod_interact2 <- lmer(yday ~ temp_90 * year + stream + I(temp_90^2) + (1 | COMID), data = model_data, REML = FALSE)
mod_interact3 <- lmer(yday ~ temp_90 * stream + temp_90 * year + I(temp_90^2) + (1 | COMID), data = model_data, REML = FALSE)
```

```{r aic-interact, caption = "AIC comparison for interactions."}
AIC(mod_quad_re, mod_interact1, mod_interact2, mod_interact3)|> 
  mutate(delta = AIC - min(AIC)) |>
  arrange(delta) |> 
  kableExtra::kbl() |>
  kableExtra::kable_styling("striped", full_width = FALSE)
```

```{r params-int, caption = "Parameter estimates for interaction models."}
tab_model(
  mod_quad_re, mod_interact1, mod_interact2, mod_interact3,
  dv.labels = c(
    "mod_quad_re", "mod_interact1", "mod_interact2", "mod_interact3"),
  CSS = list(
    css.table = "+font-size: 0.6em; +font-family: Arial;",
    css.footnote = "font-size: 0.8em;"
    )
  )
# final_models <- list(
#   mod_quad_re = mod_quad_re,
#   mod_interact1 = mod_interact1,
#   mod_interact2 = mod_interact2,
#   mod_interact3 = mod_interact3
# )
# 
# summary_list <- lapply(final_models, function(mod) {
#   data.frame(
#     AIC = AIC(mod),
#     R2 = performance::r2(mod)$R2_marginal,
#     ICC = performance::icc(mod)$ICC_adjusted
#   )
# })
# 
# summary_df <- do.call(rbind, summary_list)
# summary_df$model <- rownames(summary_df)
# summary_df <- summary_df[, c("model", "AIC", "R2", "ICC")]
# print(summary_df)
```

✅ Interpretation

-   AIC rewards `mod_interact3` the most, but the penalty in biological realism and interpretability is high.
-   `mod_quad_re` performs worst by AIC, but:
    -   It has high marginal R² (0.741) — actually higher than all interaction models
    -   Predicted fits look smoother and more interpretable (no flipped curves)
    -   It avoids noisy or sparse group-level extrapolation (which occurs in interaction models)

🔍 Fixed Effects Comparison

`temp_90`

-   Positive and highly significant in all models
-   Coefficient is largest in simpler models (e.g., `mod_quad_re` = \~15), but shrinks in complex interactions (e.g., \~0.91 in `mod_interact2`)
-   Interpretation: Adding interactions spreads the effect across groups, reducing global estimate

`temp_90^2`

-   Negative and significant in `mod_quad_re` and `mod_interact1`
    -   aligns with reality
-   Positive and significant in `mod_interact2` and `mod_interact3`
    -   does not align with reality

`stream` effects

-   Strong and significant in most models
-   Meaningful spatial differences across watersheds, consistent with field observations

`year` effects

-   Consistently significant; \~5 day shifts across years

Interaction Terms

`mod_interact1` (stream × temp)

-   Some interaction terms significant, others not
-   But interactions may amplify noise in low-data stream × temp combinations

`mod_interact2` (year × temp)

-   Interaction effects all significant
-   Suggests temporal variation in temp sensitivity — a meaningful pattern, but…
-   Could be confounded by environmental conditions already captured by year as main effect

`mod_interact3` (both)

-   Most complex
-   Likely overfitting, especially with \~25 degrees of freedom

✅ Final Recommendation

-   Stick with `mod_quad_re`
-   Balanced: interpretable, stable, and strong predictive fit
-   Interaction models:
    -   Improve AIC by brute force (more df)
    -   But reduce R², add complexity, and produce biologically odd predictions
-   Earlier, exploratory analyses confirms: interactions distort model behavior, especially in groups with narrow temp ranges

### Interogate best model

```{r select-final-mod}
mod_final <- mod_quad_re
```

```{r diagnostics}
check_model(mod_final)  # Residuals, QQ, leverage, etc.

sim_resid <- simulateResiduals(mod_final)
plot(sim_resid)  # DHARMa residual plots
```

Predictions:

```{r predictions}
# # ---------------------------------------------
# # 2a. Predictions by Stream and Year
# # ---------------------------------------------
# p_stream <- plot(ggpredict(mod_final, terms = c("temp_90 [all]", "stream"))) +
#   labs(title = "Predicted Spawn Timing by Stream",
#        x = "90-day Mean Temp",
#        y = "Predicted Spawn Day")
# 
# p_year <- plot(ggpredict(mod_final, terms = c("temp_90 [all]", "year"))) +
#   labs(title = "Predicted Spawn Timing by Year",
#        x = "90-day Mean Temp",
#        y = "Predicted Spawn Day")
# 
# print(p_stream + p_year)
# 
# # ---------------------------------------------
# # 2b. Predictions by Stream and Year with raw data
# # ---------------------------------------------
# # Recover original mean and sd from temp_90_raw
# mean_temp <- mean(model_data_final$temp_90_raw, na.rm = TRUE)
# sd_temp   <- sd(model_data_final$temp_90_raw, na.rm = TRUE)
# 
# pred_stream <- ggpredict(mod_final, terms = c("temp_90 [all]", "stream"))
# pred_stream$x_raw <- pred_stream$x * sd_temp + mean_temp
# 
# p_stream <- ggplot(pred_stream, aes(x = x_raw, y = predicted, color = group)) +
#   geom_line(linewidth = 1.1) +
#   geom_ribbon(aes(ymin = conf.low, ymax = conf.high, fill = group), alpha = 0.2, color = NA) +
#   geom_point(data = model_data_final, 
#              aes(x = temp_90_raw, y = yday, color = stream), alpha = 0.4, inherit.aes = FALSE) +
#   facet_wrap(~ group) +
#   scale_color_manual(values = cols.streams) +
#   scale_fill_manual(values = cols.streams) +
#   labs(title = "Predicted Spawn Timing by Stream with COMID as Random Int",
#        subtitle = "Model: yday ~ temp_90 * stream + year + I(temp_90^2) + (1|COMID)",
#        x = "90-day Mean Temperature (°C)",
#        y = "Predicted Spawn Day of Year") +
#   theme_minimal()
# 
# pred_year <- ggpredict(mod_final, terms = c("temp_90 [all]", "year")) 
# pred_year$x_raw <- pred_year$x * sd_temp + mean_temp
# 
# 
# p_year <- ggplot(pred_year, aes(x = x_raw, y = predicted, color = group)) +
#   geom_line(linewidth = 1.1) +
#   geom_ribbon(aes(ymin = conf.low, ymax = conf.high, fill = group), alpha = 0.2, color = NA) +
#   geom_point(data = model_data_final, 
#              aes(x = temp_90_raw, y = yday, color = factor(year)), alpha = 0.4, inherit.aes = FALSE) +
#   facet_wrap(~ group) +
#   scale_color_manual(values = cols.years) +
#   scale_fill_manual(values = cols.years) +
#   labs(title = "Predicted Spawn Timing by Year",
#        x = "90-day Mean Temperature (°C)",
#        y = "Predicted Spawn Day of Year") +
#   theme_minimal()
# 
# print(p_stream + p_year)

# ---------------------------------------------
# 2c. Predictions by Stream x Year with raw data
# ---------------------------------------------
# Create newdata grid of temp_90 and each stream × year combination
pred_grid <- expand.grid(
  temp_90_raw = seq(min(model_data_final$temp_90_raw), max(model_data_final$temp_90_raw), length.out = 100),
  stream = unique(model_data_final$stream),
  year = unique(model_data_final$year)
)

# Scale temp_90_raw using stored mean and sd
pred_grid$temp_90 <- (pred_grid$temp_90_raw - mean_temp) / sd_temp

# Predict using fixed effects only (exclude COMID random intercepts)
pred_grid$pred <- predict(mod_final, newdata = pred_grid, re.form = NA)
# new_data$pred <- pred_out$fit
# new_data$lower <- pred_out$fit - 1.96 * pred_out$se.fit
# new_data$upper <- pred_out$fit + 1.96 * pred_out$se.fit

# Plot
ggplot() +
  geom_point(data = model_data_final, aes(x = temp_90_raw, y = yday), alpha = 0.5, color = "black") +
  geom_line(data = pred_grid, aes(x = temp_90_raw, y = pred), color = "blue") +
  facet_grid(stream ~ year, labeller = label_both) +
  labs(title = "Predicted Spawn Timing by Stream and Year",
       subtitle = "Model: yday ~ temp_90 * stream + year + I(temp_90^2) + (1 | COMID)",
       x = "90-day Mean Temperature (°C)",
       y = "Predicted Spawn Day of Year") +
  theme_minimal()
```

Model Fit is Generally Good

-   But Not Uniform Most panels show close alignment between predicted lines and observed points.
-   Predicted curves track the central tendency well, especially in moderate data-rich combinations (e.g., Bear Valley, Big, Camas in 2002–2004).

Stream-Specific Offsets

-   Suggest COMID-Level Variation Some systematic offsets are still visible even with COMID as a random effect.
-   For example:
    -   Big–2003 and Big–2004: late spawners fall below the curve.
    -   Camas–2002: points are above the curve (earlier spawn than predicted).
-   These likely reflect within-stream heterogeneity (i.e., differences between upper/lower reaches of Big, Camas, etc.).
-   Earlier instinct is right: a single stream-level fixed effect may be too coarse.
-   In these cases, random slopes by COMID might help, if data allow.

Slight Misses in 2005 In multiple streams, predictions for 2005 fall below the data (underpredict spawn timing).

-   The model’s estimate for year2005 might be biased low.
-   It could also reflect that temp_90 doesn't fully capture 2005’s phenology (e.g., abrupt weather changes, flow anomalies).

Curve Shape Holds Up The nonlinear (quadratic) fit looks appropriate:

-   Predictions plateau at higher temps, consistent with biological expectations (i.e., spawn date doesn’t keep shifting endlessly later with more heat).
-   Curvature seems realistic and improves over a purely linear model.

Takeaways

-   (temp_90 \* stream + year + I(temp_90\^2) + (1 \| COMID)) is doing well overall.

But:

-   Some groups still show local deviation, especially large systems (e.g., Big, Camas).
-   Consider adding random slopes for temp_90 by COMID in exploratory models (with caution due to data sparsity).
-   Alternatively, split streams like Big into upper/lower reaches if COMID-specific slope estimation isn’t feasible.

Residuals vs COMID:

```{r residuals}
# --- Step 1: Add predicted values and residuals ---
model_data_final$resid <- residuals(mod_final)
model_data_final$pred <- predict(mod_final)


ggplot(model_data_final, aes(x = reorder(COMID, resid, FUN = median), y = resid)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(width = 0.2, alpha = 0.3) +
  facet_wrap(~stream, scales = "free_x") +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(x = "COMID", y = "Residual (Observed - Predicted)", title = "Residuals by COMID") +
  theme_minimal() +
  # coord_flip() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))


# Identify Outlier Observations Within COMIDs
# You could flag specific observations like this:

model_data_final <- model_data_final %>%
  mutate(outlier_obs = abs(resid) > 2)  # or 3 if you want stricter filtering

# Then you can examine:
# 
# Which years or streams have repeated outliers?
# 
# Are outliers clustered in particular COMIDs, or dispersed?


# comid_resids <- model_data_final %>%
#   group_by(COMID) %>%
#   summarise(
#     mean_resid = mean(resid, na.rm = TRUE),
#     n = n()
#   ) %>%
#   mutate(outlier = abs(mean_resid) > 3)
# 
# ggplot(comid_resids, aes(x = reorder(COMID, mean_resid), y = mean_resid, fill = outlier)) +
#   geom_col() +
#   scale_fill_manual(values = c("FALSE" = "gray70", "TRUE" = "red")) +
#   geom_hline(yintercept = 0, linetype = "dashed") +
#   labs(title = "Mean Model Residual by COMID",
#        subtitle = "Outliers defined as |residual| > 3",
#        x = "COMID",
#        y = "Mean Residual (Observed - Predicted)") +
#   coord_flip() +
#   theme_minimal()
```

Most COMIDs centered near zero: model’s predictions are largely unbiased for those groups.

Tight spread: Many COMIDs, especially in streams like Elk, Beaver, and Sulphur, show tight interquartile ranges and few extreme points → good fit, low noise.

High Variance or Systematic Bias - Camas: Several COMIDs show consistent positive bias (observed \> predicted) with large IQRs and - - numerous outliers → possible issues with unmodeled local effects or over-aggregated structure.

Big and Loon: - A few COMIDs have long tails, asymmetric spread, or both — suggests within-stream heterogeneity (e.g., distinct upper/lower reaches) that’s not being fully captured by stream alone.

Potential Outlier COMIDs - Some COMIDs (e.g., in Camas, Loon, and Big) have medians far from zero and high variance.

These may benefit from random slopes or hierarchical nesting like (1\|stream/COMID) to account for sub-stream structure.

```{r}
# ---------------------------------------------
# 3. Summary Table for Reporting
# ---------------------------------------------
final_summary <- data.frame(
  AIC = AIC(mod_final),
  R2_marginal = r2(mod_final)$R2_marginal,
  R2_conditional = r2(mod_final)$R2_conditional,
  ICC = performance::icc(mod_final)$ICC_adjusted,
  df = length(fixef(mod_final)) + 1  # intercept + fixed effects
)
print(final_summary)

# Fixed effects summary
final_coef <- broom.mixed::tidy(mod_final, effects = "fixed")
print(final_coef)

final_coef_re <- ranef(mod_quad_re)$COMID
final_coef_re$COMID <- rownames(final_coef_re)
colnames(final_coef_re)[1] <- "intercept"
ggplot(final_coef_re, aes(x = reorder(COMID, intercept), y = intercept)) +
  geom_point() + coord_flip() +
  labs(title = "Random Intercepts by COMID", x = "COMID", y = "Random Effect Estimate") +
  theme_bw()
# ---------------------------------------------
# 4. Summary Paragraph
# ---------------------------------------------
cat("\nModel Summary (mod_quad_re):\n")
cat("We modeled Chinook salmon spawn timing (day of year) using 90-day mean stream temperature, its quadratic effect, stream, and year, with COMID included as a random intercept (n = 3013 observations, 103 COMIDs). The final model showed strong fit (AIC =", round(AIC(mod_final), 2), ", marginal R² =", round(r2(mod_final)$R2_marginal, 3), ", ICC =", round(performance::icc(mod_final)$ICC_adjusted, 2), "). Predictions increased nonlinearly with temperature and varied strongly by stream and year. Elevation and interaction terms were evaluated but ultimately excluded due to limited performance gains or interpretability.\n")
```
