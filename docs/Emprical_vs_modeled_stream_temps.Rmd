---
title: "MFSR Stream Temps: Empirical vs. Siegel"
output:
  html_document:
    toc: true
    number_sections: true
    toc_depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: false
date: "2025-05-12"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      warning = FALSE)

library(tidyverse)

### load data
# siegel_temp <- readRDS("../data/siegel_temperature/siegel_mfsr.rds")
# 
# empirical_temp <- readxl::read_xlsx("../data/mfsr_empirical_temps.xlsx", sheet = 2)
```

## Justification

Since we have good empirical data from within the basin and around Idaho it makes sense to compare how well Siegel's model fits our empirical data. But we have a couple different options we will explore below:

```{r data_import}

#make tim.date into a date for merging
# siegel_temp <- siegel_temp |> 
#   mutate(SampleDate = as_date(tim.date, tz = "UTC"))
# 
# #left_join to empirical and drop NAs
# all_temps <- empirical_temp |>
#   left_join(siegel_temp, by = join_by(COMID, SampleDate)) |>
#   drop_na(prd.stream_temp) |> 
#   filter(DAILY_AVG_TEMP_C >= -1)
# 
# write.csv(all_temps , "Emprical_vs_modeled_stream_temps_files/all_temps.csv")
  
# above is commented out because join on full siegel took forever so just wrote out a csv
all_temps <- read_csv("./Emprical_vs_modeled_stream_temps_files/all_temps.csv")

```

## Compare with Gwynne's archival data

First, we will load in the data provided by Gwynne from the archives she dug up (not sure provenance of this data.

### Consider all sites

Gwynne's data has a lot more sites than we have spawning locations. So we'll first consider the whole basin.

#### Fit by stream

```{r gwynne-summary, fig.width=14, fig.height=16}
all_temps|> 
  mutate(year = year(SampleDate)) |> 
  ggplot(aes(y = prd.stream_temp, x = DAILY_AVG_TEMP_C, color = StreamName)) +
  geom_abline(intercept = 0, slope = 1) +
  geom_point(size = 0.1) +
  geom_smooth(method = "lm", se = FALSE) +
  facet_wrap(~StreamName) +
  labs(x = "Empirical Temperature (째C)", y = "Predicted Temperature (째C)") +
  theme_bw() +
  theme(legend.position = "none")
```

#### Fit for all sites

```{r plot-gwynne-1}

all_temps |> 
  ggplot(aes(x= DAILY_AVG_TEMP_C , y = prd.stream_temp)) +
  geom_point(size = 0.15) +
  geom_smooth(method = "lm", se = FALSE) +
  geom_abline(intercept = 0, slope = 1) +
  labs(x = "Empirical Temp", y ="Predicted Temp",
       title = "All sites") +
  theme_bw()

```

#### Visualize Temp \~ Stream and Month

```{r plot-gwynne-2, fig.width=12, fig.height=12}

all_temps |> 
  mutate(month = as.factor(month(SampleDate))) |> 
  ggplot(aes(x= DAILY_AVG_TEMP_C , y = prd.stream_temp, color = StreamName)) +
  #geom_point(size = 0.01) +
  geom_smooth(method = "lm", se = FALSE) +
  geom_abline(intercept = 0, slope = 1) +
  facet_wrap(~ month) +
  labs(x = "Empirical Temp", y ="Predicted Temp",
       title = "Relationship by Month and Stream ") +
  theme_bw() +
  theme(legend.position = "none")
```

#### Model Fit

We can look at the model fit (*R\^2 = 0.718*):

```{r, echo=TRUE}
mod_gwynne<- lm(DAILY_AVG_TEMP_C ~ prd.stream_temp , data = all_temps)

sjPlot::tab_model(mod_gwynne)
```

### Fit by spawning data

An alternative would be just to look in COMIDs that have redds in them:

```{r}
siegel_spawn_comids <- readRDS("../data/siegel_temperature/siegel_mfsr_comid.RDS")
spawn_comids <- unique(siegel_spawn_comids$COMID)

all_temps_spawn <- all_temps |> 
  filter(COMID %in% spawn_comids &
         StreamName != "Knapp Creek" &
         StreamName != "Castle Creek" &
         StreamName != "Cape Horn Creek")

```

#### Fit by stream

```{r gwynne-summary-spawn}
all_temps_spawn|> 
  mutate(year = year(SampleDate)) |> 
  ggplot(aes(y = prd.stream_temp, x = DAILY_AVG_TEMP_C, color = StreamName)) +
  geom_abline(intercept = 0, slope = 1) +
  geom_point(size = 0.1) +
  geom_smooth(method = "lm", se = FALSE) +
  facet_wrap(~StreamName) +
  labs(x = "Empirical Temperature (째C)", y = "Predicted Temperature (째C)") +
  theme_bw() +
  theme(legend.position = "none")
```

#### Visualize Temp \~ Month + Stream

```{r plot-gwynne-spawn-2}

all_temps_spawn |> 
  mutate(month = as.factor(month(SampleDate))) |> 
  ggplot(aes(x= DAILY_AVG_TEMP_C , y = prd.stream_temp, color = StreamName)) +
  #geom_point(size = 0.01) +
  geom_smooth(method = "lm", se = FALSE) +
  geom_abline(intercept = 0, slope = 1) +
  facet_wrap(~ month) +
  labs(x = "Empirical Temp", y ="Predicted Temp",
       title = "Relationship by Month and Stream ") +
  theme_bw() +
  theme(legend.position = "none")
```

#### Model fit

Model performs slightly worse by R\^2 when we take it down just to spawning locations.

```{r model-fit-spawn}

mod_gwynne_spawn<- lm(DAILY_AVG_TEMP_C ~ prd.stream_temp , data = all_temps_spawn)

sjPlot::tab_model(mod_gwynne_spawn)
```

## Idaho Data

An alternative option is to compare with Dan's 2018 dataset which has hundreds of sites

### Model

```{r isaak-model}
isaak_siegel <- readRDS("../data/siegel_temperature/Isaak_Siegel_Compare.rds")
isaak_siegel <- isaak_siegel |> 
  drop_na(DailyMean, Stream_Temp)

is_mod <- lm(DailyMean~Stream_Temp, data = isaak_siegel)
sjPlot::tab_model(is_mod)

```

### Model Plot

```{r isaak-model-plot}
isaak_siegel |> 
  mutate(date = mdy(SampleDate),
         month = as.factor(month(date))) |> 
  ggplot(aes(x= DailyMean , y = Stream_Temp)) +
  geom_point(size = 0.01) +
  geom_smooth(method = "lm") +
  geom_abline(intercept = 0, slope = 1) +
  labs(x = "Empirical Temp", y ="Predicted Temp") +
  theme_bw()
```

### Isaak fit by month

```{r isaak-plot1}

isaak_siegel |> 
  mutate(date = mdy(SampleDate),
         month = as.factor(month(date))) |> 
  ggplot(aes(x= DailyMean , y = Stream_Temp, color = month)) +
  geom_point(size = 0.01, alpha= 0.01) +
  geom_smooth(method = "lm") +
  geom_abline(intercept = 0, slope = 1) +
  facet_wrap(~month) +
  labs(x = "Empirical Temp", y ="Predicted Temp") +
  theme_bw() +
  theme(legend.position = "none")

```

## Summary

The basic tradeoff here is Gwynne's data are in basin but only cover summer months (see table below). However, we could instead use Dan's 2018 data, the benefit being it has multiple years of data across the exact same dates. The downside being none of the sites are in the Middle Fork Salmon.

```{r mfsr-summ-table}
all_temps |> 
  mutate(year = year(SampleDate)) |> 
  group_by(StreamName, year) |> 
    summarise(max_date = max(SampleDate),
              min_date = min(SampleDate),
              days = max_date-min_date) |> 
  kableExtra::kbl() |> 
  kableExtra::kable_styling("striped", full_width = F)
```
